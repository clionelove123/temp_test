{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPe7JSBjUX6AyztAUnkg109",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clionelove123/temp_test/blob/main/Chap_01_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "R2FGfFSH8F0D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "_jWKdPlR8QSz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "iMFiA_sC8QdQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지합니다.\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVprwCfp8TZ4",
        "outputId": "11d894ff-fcd6-4acf-e76c-c5dd36d48ce4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.7315, 0.2357],\n",
            "        [0.8702, 0.6066]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g92wlbI88Tce",
        "outputId": "2e30bee1-fa8f-458d-fe6b-6c07dc6bf84b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.5769, 0.1568, 0.6008],\n",
            "        [0.2209, 0.9731, 0.5108]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBzmJisj8Te-",
        "outputId": "d67fde3b-0c15-4e93-f59a-2aa6c7d4a001"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU가 존재하면 텐서를 이동합니다\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")"
      ],
      "metadata": {
        "id": "uL2FU_oq8ThX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejHCLnQ58Tjr",
        "outputId": "6f397ac7-c9f4-45ee-a352-4a4b9210509b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvcLiDJY8Tl-",
        "outputId": "cb9a49af-799a-43cf-dd51-42758250c9e3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
        "# ``tensor.T`` 는 텐서의 전치(transpose)를 반환합니다.\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "print(y1)\n",
        "print(y2)\n",
        "print(y3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gggHDVB8auF",
        "outputId": "7c252bb1-77fe-482e-f8c3-0f4d611f30fc"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n",
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n",
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)\n",
        "\n",
        "print(z1)\n",
        "print(z2)\n",
        "print(z3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvacZs7_HXz8",
        "outputId": "1a9da5cd-afc1-4eb2-8d5a-a57d249bd3f1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "C5SlxvDX8hcs"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "ZjHnE4rS8he9",
        "outputId": "665963d7-cd1e-4014-dc63-0f396f491d11"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'])\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "7j3qZrqr8hhh"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "ZqZ2I7No8awx"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지와 정답(label)을 표시합니다.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "AWvlNYKA8azL",
        "outputId": "ad2eac88-970b-4cd1-d711-29b250262033"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "z = torch.matmul(x, w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ],
      "metadata": {
        "id": "muLlUvMg84bK"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPtKhOep84d0",
        "outputId": "7fc0c557-29ad-40f7-f5dc-368de92ac8cb"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7f4290802830>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f4290802e00>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USKp98wL84gP",
        "outputId": "59cc5b70-7112-4c8e-dd17-b74e2837a656"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0371, 0.2281, 0.0834],\n",
            "        [0.0371, 0.2281, 0.0834],\n",
            "        [0.0371, 0.2281, 0.0834],\n",
            "        [0.0371, 0.2281, 0.0834],\n",
            "        [0.0371, 0.2281, 0.0834]])\n",
            "tensor([0.0371, 0.2281, 0.0834])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "P4dEfGWF-Kao"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkLHRtoB-Kdn",
        "outputId": "f8f07145-7668-4ac2-bd43-1529eb6413a8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "D6Is8tuK-Kf2"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iIKf3eh-Kh_",
        "outputId": "5e636cc2-e3bc-4bdb-94bd-8c8a8634dd9d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4F1CnxM-Kkk",
        "outputId": "0ca88081-93ce-4079-81b1-61e9c06305da"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([1], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unEaokJW-P3H",
        "outputId": "e5e04a16-1478-4bcc-e3a2-654087b25f2f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsnLiDRx-Kmh",
        "outputId": "355185ac-2e1d-4550-93d3-9d7a3d58d655"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p25YVmcx-Kox",
        "outputId": "2d7a0a37-9537-4e34-fa9c-2223189081ea"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJbwnXWG-KrX",
        "outputId": "a750abb8-39fc-4414-bf9f-a8ac09aa1868"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[-0.5262, -0.5098,  0.5673,  0.1327, -0.2566, -0.6220,  0.1287,  0.0529,\n",
            "          0.4500, -0.6629, -0.4774, -0.0362, -0.1310,  0.3666, -0.0206, -0.0646,\n",
            "         -0.5944, -0.1236,  0.0515,  0.1258],\n",
            "        [-0.8552, -0.4503,  0.3723,  0.4290, -0.2201, -0.4944,  0.2724,  0.2022,\n",
            "          0.5288, -0.7687, -0.4276,  0.0681,  0.2324,  0.3867, -0.3110, -0.0285,\n",
            "         -0.7999, -0.0235,  0.0071,  0.0583],\n",
            "        [-0.4828, -0.7619,  0.4120,  0.4863, -0.3015, -0.4763,  0.2964,  0.1282,\n",
            "          0.2161, -0.6715, -0.4867, -0.0463, -0.0483,  0.3339, -0.2435, -0.4297,\n",
            "         -0.6015, -0.0908, -0.4126,  0.0547]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.0000, 0.0000, 0.5673, 0.1327, 0.0000, 0.0000, 0.1287, 0.0529, 0.4500,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.3666, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0515, 0.1258],\n",
            "        [0.0000, 0.0000, 0.3723, 0.4290, 0.0000, 0.0000, 0.2724, 0.2022, 0.5288,\n",
            "         0.0000, 0.0000, 0.0681, 0.2324, 0.3867, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0071, 0.0583],\n",
            "        [0.0000, 0.0000, 0.4120, 0.4863, 0.0000, 0.0000, 0.2964, 0.1282, 0.2161,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.3339, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0547]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ],
      "metadata": {
        "id": "i698tKYr-Ktz"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ],
      "metadata": {
        "id": "kCY2Twcj-W1_"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIBW4ut7-W45",
        "outputId": "6dcd8cc8-c6fb-4fc6-e199-b256a28574ac"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0341, -0.0347, -0.0220,  ...,  0.0303,  0.0187, -0.0180],\n",
            "        [-0.0281, -0.0109,  0.0023,  ...,  0.0120,  0.0124, -0.0018]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0266, -0.0040], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0239,  0.0195,  0.0160,  ..., -0.0140, -0.0143,  0.0319],\n",
            "        [-0.0079, -0.0362,  0.0366,  ..., -0.0078,  0.0307, -0.0017]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0223, 0.0175], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0215, -0.0216,  0.0146,  ...,  0.0194, -0.0040,  0.0366],\n",
            "        [ 0.0257, -0.0045, -0.0291,  ..., -0.0087,  0.0378, -0.0196]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0127, -0.0249], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "T86F6Nmp84iq"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "YW61gg1o9XiF"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수를 초기화합니다.\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CmpLaFtC9Xkh"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "UaatuGI09Xm9"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # 예측(prediction)과 손실(loss) 계산\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "AMXR_S-n9XpG"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s3sBM1A9XsG",
        "outputId": "e3d9658a-f4c7-4b8c-985e-76ecb121b518"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.804638  [   64/60000]\n",
            "loss: 0.878480  [ 6464/60000]\n",
            "loss: 0.643198  [12864/60000]\n",
            "loss: 0.847378  [19264/60000]\n",
            "loss: 0.736601  [25664/60000]\n",
            "loss: 0.738107  [32064/60000]\n",
            "loss: 0.809320  [38464/60000]\n",
            "loss: 0.796007  [44864/60000]\n",
            "loss: 0.801225  [51264/60000]\n",
            "loss: 0.769507  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.9%, Avg loss: 0.767576 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.766562  [   64/60000]\n",
            "loss: 0.848637  [ 6464/60000]\n",
            "loss: 0.610727  [12864/60000]\n",
            "loss: 0.822588  [19264/60000]\n",
            "loss: 0.714384  [25664/60000]\n",
            "loss: 0.712114  [32064/60000]\n",
            "loss: 0.783718  [38464/60000]\n",
            "loss: 0.778941  [44864/60000]\n",
            "loss: 0.777770  [51264/60000]\n",
            "loss: 0.747549  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 0.744881 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.733177  [   64/60000]\n",
            "loss: 0.821892  [ 6464/60000]\n",
            "loss: 0.582891  [12864/60000]\n",
            "loss: 0.801734  [19264/60000]\n",
            "loss: 0.695237  [25664/60000]\n",
            "loss: 0.690651  [32064/60000]\n",
            "loss: 0.760538  [38464/60000]\n",
            "loss: 0.763912  [44864/60000]\n",
            "loss: 0.757521  [51264/60000]\n",
            "loss: 0.728105  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 74.0%, Avg loss: 0.724809 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.703419  [   64/60000]\n",
            "loss: 0.797403  [ 6464/60000]\n",
            "loss: 0.558600  [12864/60000]\n",
            "loss: 0.783385  [19264/60000]\n",
            "loss: 0.678370  [25664/60000]\n",
            "loss: 0.672509  [32064/60000]\n",
            "loss: 0.739086  [38464/60000]\n",
            "loss: 0.750071  [44864/60000]\n",
            "loss: 0.739723  [51264/60000]\n",
            "loss: 0.710583  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 74.9%, Avg loss: 0.706676 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.676615  [   64/60000]\n",
            "loss: 0.774747  [ 6464/60000]\n",
            "loss: 0.537118  [12864/60000]\n",
            "loss: 0.766913  [19264/60000]\n",
            "loss: 0.663361  [25664/60000]\n",
            "loss: 0.657035  [32064/60000]\n",
            "loss: 0.719112  [38464/60000]\n",
            "loss: 0.737268  [44864/60000]\n",
            "loss: 0.724053  [51264/60000]\n",
            "loss: 0.694573  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 75.8%, Avg loss: 0.690144 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.652491  [   64/60000]\n",
            "loss: 0.753792  [ 6464/60000]\n",
            "loss: 0.517971  [12864/60000]\n",
            "loss: 0.751904  [19264/60000]\n",
            "loss: 0.650010  [25664/60000]\n",
            "loss: 0.643672  [32064/60000]\n",
            "loss: 0.700490  [38464/60000]\n",
            "loss: 0.725485  [44864/60000]\n",
            "loss: 0.709911  [51264/60000]\n",
            "loss: 0.679770  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 76.6%, Avg loss: 0.674941 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.630822  [   64/60000]\n",
            "loss: 0.734554  [ 6464/60000]\n",
            "loss: 0.500777  [12864/60000]\n",
            "loss: 0.738145  [19264/60000]\n",
            "loss: 0.638103  [25664/60000]\n",
            "loss: 0.631979  [32064/60000]\n",
            "loss: 0.683120  [38464/60000]\n",
            "loss: 0.714668  [44864/60000]\n",
            "loss: 0.697281  [51264/60000]\n",
            "loss: 0.665989  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.3%, Avg loss: 0.660918 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.611472  [   64/60000]\n",
            "loss: 0.716758  [ 6464/60000]\n",
            "loss: 0.485232  [12864/60000]\n",
            "loss: 0.725439  [19264/60000]\n",
            "loss: 0.627441  [25664/60000]\n",
            "loss: 0.621778  [32064/60000]\n",
            "loss: 0.666874  [38464/60000]\n",
            "loss: 0.704898  [44864/60000]\n",
            "loss: 0.686115  [51264/60000]\n",
            "loss: 0.653177  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 0.648016 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.593973  [   64/60000]\n",
            "loss: 0.700227  [ 6464/60000]\n",
            "loss: 0.471310  [12864/60000]\n",
            "loss: 0.713669  [19264/60000]\n",
            "loss: 0.617824  [25664/60000]\n",
            "loss: 0.612700  [32064/60000]\n",
            "loss: 0.651802  [38464/60000]\n",
            "loss: 0.696255  [44864/60000]\n",
            "loss: 0.676368  [51264/60000]\n",
            "loss: 0.641133  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 0.636144 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.578194  [   64/60000]\n",
            "loss: 0.684931  [ 6464/60000]\n",
            "loss: 0.458734  [12864/60000]\n",
            "loss: 0.702709  [19264/60000]\n",
            "loss: 0.609131  [25664/60000]\n",
            "loss: 0.604590  [32064/60000]\n",
            "loss: 0.637882  [38464/60000]\n",
            "loss: 0.688724  [44864/60000]\n",
            "loss: 0.667758  [51264/60000]\n",
            "loss: 0.629727  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 0.625233 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.563923  [   64/60000]\n",
            "loss: 0.670898  [ 6464/60000]\n",
            "loss: 0.447353  [12864/60000]\n",
            "loss: 0.692340  [19264/60000]\n",
            "loss: 0.601223  [25664/60000]\n",
            "loss: 0.597259  [32064/60000]\n",
            "loss: 0.624977  [38464/60000]\n",
            "loss: 0.682296  [44864/60000]\n",
            "loss: 0.660206  [51264/60000]\n",
            "loss: 0.618977  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.7%, Avg loss: 0.615195 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.550890  [   64/60000]\n",
            "loss: 0.657954  [ 6464/60000]\n",
            "loss: 0.436983  [12864/60000]\n",
            "loss: 0.682573  [19264/60000]\n",
            "loss: 0.593804  [25664/60000]\n",
            "loss: 0.590582  [32064/60000]\n",
            "loss: 0.613035  [38464/60000]\n",
            "loss: 0.676851  [44864/60000]\n",
            "loss: 0.653611  [51264/60000]\n",
            "loss: 0.608762  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.0%, Avg loss: 0.605952 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.538945  [   64/60000]\n",
            "loss: 0.645998  [ 6464/60000]\n",
            "loss: 0.427417  [12864/60000]\n",
            "loss: 0.673378  [19264/60000]\n",
            "loss: 0.586847  [25664/60000]\n",
            "loss: 0.584494  [32064/60000]\n",
            "loss: 0.602072  [38464/60000]\n",
            "loss: 0.672405  [44864/60000]\n",
            "loss: 0.647824  [51264/60000]\n",
            "loss: 0.599025  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.2%, Avg loss: 0.597436 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.527942  [   64/60000]\n",
            "loss: 0.634946  [ 6464/60000]\n",
            "loss: 0.418620  [12864/60000]\n",
            "loss: 0.664672  [19264/60000]\n",
            "loss: 0.580229  [25664/60000]\n",
            "loss: 0.578872  [32064/60000]\n",
            "loss: 0.592027  [38464/60000]\n",
            "loss: 0.668849  [44864/60000]\n",
            "loss: 0.642734  [51264/60000]\n",
            "loss: 0.589673  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.5%, Avg loss: 0.589571 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.517762  [   64/60000]\n",
            "loss: 0.624692  [ 6464/60000]\n",
            "loss: 0.410510  [12864/60000]\n",
            "loss: 0.656392  [19264/60000]\n",
            "loss: 0.573927  [25664/60000]\n",
            "loss: 0.573543  [32064/60000]\n",
            "loss: 0.582744  [38464/60000]\n",
            "loss: 0.666185  [44864/60000]\n",
            "loss: 0.638224  [51264/60000]\n",
            "loss: 0.580635  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.7%, Avg loss: 0.582293 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.508233  [   64/60000]\n",
            "loss: 0.615221  [ 6464/60000]\n",
            "loss: 0.402968  [12864/60000]\n",
            "loss: 0.648437  [19264/60000]\n",
            "loss: 0.567741  [25664/60000]\n",
            "loss: 0.568414  [32064/60000]\n",
            "loss: 0.574178  [38464/60000]\n",
            "loss: 0.664341  [44864/60000]\n",
            "loss: 0.634267  [51264/60000]\n",
            "loss: 0.571894  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.9%, Avg loss: 0.575546 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.499333  [   64/60000]\n",
            "loss: 0.606401  [ 6464/60000]\n",
            "loss: 0.395909  [12864/60000]\n",
            "loss: 0.640819  [19264/60000]\n",
            "loss: 0.561696  [25664/60000]\n",
            "loss: 0.563391  [32064/60000]\n",
            "loss: 0.566183  [38464/60000]\n",
            "loss: 0.663092  [44864/60000]\n",
            "loss: 0.630654  [51264/60000]\n",
            "loss: 0.563439  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.1%, Avg loss: 0.569278 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.490930  [   64/60000]\n",
            "loss: 0.598274  [ 6464/60000]\n",
            "loss: 0.389223  [12864/60000]\n",
            "loss: 0.633554  [19264/60000]\n",
            "loss: 0.555722  [25664/60000]\n",
            "loss: 0.558422  [32064/60000]\n",
            "loss: 0.558758  [38464/60000]\n",
            "loss: 0.662219  [44864/60000]\n",
            "loss: 0.627429  [51264/60000]\n",
            "loss: 0.555302  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.4%, Avg loss: 0.563438 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.482945  [   64/60000]\n",
            "loss: 0.590748  [ 6464/60000]\n",
            "loss: 0.382911  [12864/60000]\n",
            "loss: 0.626632  [19264/60000]\n",
            "loss: 0.549865  [25664/60000]\n",
            "loss: 0.553523  [32064/60000]\n",
            "loss: 0.551956  [38464/60000]\n",
            "loss: 0.661861  [44864/60000]\n",
            "loss: 0.624478  [51264/60000]\n",
            "loss: 0.547399  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.6%, Avg loss: 0.558004 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.475456  [   64/60000]\n",
            "loss: 0.583717  [ 6464/60000]\n",
            "loss: 0.377040  [12864/60000]\n",
            "loss: 0.620030  [19264/60000]\n",
            "loss: 0.544159  [25664/60000]\n",
            "loss: 0.548703  [32064/60000]\n",
            "loss: 0.545688  [38464/60000]\n",
            "loss: 0.661779  [44864/60000]\n",
            "loss: 0.621737  [51264/60000]\n",
            "loss: 0.539708  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.8%, Avg loss: 0.552953 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.468224  [   64/60000]\n",
            "loss: 0.577158  [ 6464/60000]\n",
            "loss: 0.371668  [12864/60000]\n",
            "loss: 0.613675  [19264/60000]\n",
            "loss: 0.538590  [25664/60000]\n",
            "loss: 0.544222  [32064/60000]\n",
            "loss: 0.539789  [38464/60000]\n",
            "loss: 0.662028  [44864/60000]\n",
            "loss: 0.619235  [51264/60000]\n",
            "loss: 0.532347  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.9%, Avg loss: 0.548235 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.461321  [   64/60000]\n",
            "loss: 0.571108  [ 6464/60000]\n",
            "loss: 0.366657  [12864/60000]\n",
            "loss: 0.607605  [19264/60000]\n",
            "loss: 0.533032  [25664/60000]\n",
            "loss: 0.539829  [32064/60000]\n",
            "loss: 0.534298  [38464/60000]\n",
            "loss: 0.662502  [44864/60000]\n",
            "loss: 0.616857  [51264/60000]\n",
            "loss: 0.525194  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 0.543823 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.454770  [   64/60000]\n",
            "loss: 0.565510  [ 6464/60000]\n",
            "loss: 0.361938  [12864/60000]\n",
            "loss: 0.601766  [19264/60000]\n",
            "loss: 0.527583  [25664/60000]\n",
            "loss: 0.535471  [32064/60000]\n",
            "loss: 0.529199  [38464/60000]\n",
            "loss: 0.663085  [44864/60000]\n",
            "loss: 0.614553  [51264/60000]\n",
            "loss: 0.518286  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 0.539684 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.448517  [   64/60000]\n",
            "loss: 0.560325  [ 6464/60000]\n",
            "loss: 0.357487  [12864/60000]\n",
            "loss: 0.596161  [19264/60000]\n",
            "loss: 0.522271  [25664/60000]\n",
            "loss: 0.531205  [32064/60000]\n",
            "loss: 0.524444  [38464/60000]\n",
            "loss: 0.663725  [44864/60000]\n",
            "loss: 0.612356  [51264/60000]\n",
            "loss: 0.511659  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.2%, Avg loss: 0.535795 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.442522  [   64/60000]\n",
            "loss: 0.555486  [ 6464/60000]\n",
            "loss: 0.353287  [12864/60000]\n",
            "loss: 0.590790  [19264/60000]\n",
            "loss: 0.517079  [25664/60000]\n",
            "loss: 0.526999  [32064/60000]\n",
            "loss: 0.519959  [38464/60000]\n",
            "loss: 0.664365  [44864/60000]\n",
            "loss: 0.610213  [51264/60000]\n",
            "loss: 0.505267  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.532134 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.436784  [   64/60000]\n",
            "loss: 0.550960  [ 6464/60000]\n",
            "loss: 0.349315  [12864/60000]\n",
            "loss: 0.585639  [19264/60000]\n",
            "loss: 0.512041  [25664/60000]\n",
            "loss: 0.522897  [32064/60000]\n",
            "loss: 0.515769  [38464/60000]\n",
            "loss: 0.665008  [44864/60000]\n",
            "loss: 0.608132  [51264/60000]\n",
            "loss: 0.499155  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.528680 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.431265  [   64/60000]\n",
            "loss: 0.546719  [ 6464/60000]\n",
            "loss: 0.345585  [12864/60000]\n",
            "loss: 0.580719  [19264/60000]\n",
            "loss: 0.507129  [25664/60000]\n",
            "loss: 0.518850  [32064/60000]\n",
            "loss: 0.511796  [38464/60000]\n",
            "loss: 0.665570  [44864/60000]\n",
            "loss: 0.606104  [51264/60000]\n",
            "loss: 0.493272  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.525415 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.425980  [   64/60000]\n",
            "loss: 0.542767  [ 6464/60000]\n",
            "loss: 0.342047  [12864/60000]\n",
            "loss: 0.576010  [19264/60000]\n",
            "loss: 0.502365  [25664/60000]\n",
            "loss: 0.514907  [32064/60000]\n",
            "loss: 0.508020  [38464/60000]\n",
            "loss: 0.666028  [44864/60000]\n",
            "loss: 0.604099  [51264/60000]\n",
            "loss: 0.487653  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.522323 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.420894  [   64/60000]\n",
            "loss: 0.539049  [ 6464/60000]\n",
            "loss: 0.338667  [12864/60000]\n",
            "loss: 0.571504  [19264/60000]\n",
            "loss: 0.497753  [25664/60000]\n",
            "loss: 0.511061  [32064/60000]\n",
            "loss: 0.504427  [38464/60000]\n",
            "loss: 0.666330  [44864/60000]\n",
            "loss: 0.602180  [51264/60000]\n",
            "loss: 0.482289  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.6%, Avg loss: 0.519391 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.415975  [   64/60000]\n",
            "loss: 0.535533  [ 6464/60000]\n",
            "loss: 0.335463  [12864/60000]\n",
            "loss: 0.567160  [19264/60000]\n",
            "loss: 0.493222  [25664/60000]\n",
            "loss: 0.507330  [32064/60000]\n",
            "loss: 0.501005  [38464/60000]\n",
            "loss: 0.666452  [44864/60000]\n",
            "loss: 0.600268  [51264/60000]\n",
            "loss: 0.477199  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.6%, Avg loss: 0.516604 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.411180  [   64/60000]\n",
            "loss: 0.532210  [ 6464/60000]\n",
            "loss: 0.332392  [12864/60000]\n",
            "loss: 0.562987  [19264/60000]\n",
            "loss: 0.488838  [25664/60000]\n",
            "loss: 0.503685  [32064/60000]\n",
            "loss: 0.497723  [38464/60000]\n",
            "loss: 0.666468  [44864/60000]\n",
            "loss: 0.598405  [51264/60000]\n",
            "loss: 0.472392  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 0.513949 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.406506  [   64/60000]\n",
            "loss: 0.529083  [ 6464/60000]\n",
            "loss: 0.329477  [12864/60000]\n",
            "loss: 0.558997  [19264/60000]\n",
            "loss: 0.484562  [25664/60000]\n",
            "loss: 0.500174  [32064/60000]\n",
            "loss: 0.494587  [38464/60000]\n",
            "loss: 0.666351  [44864/60000]\n",
            "loss: 0.596568  [51264/60000]\n",
            "loss: 0.467815  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 0.511416 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.401976  [   64/60000]\n",
            "loss: 0.526115  [ 6464/60000]\n",
            "loss: 0.326686  [12864/60000]\n",
            "loss: 0.555175  [19264/60000]\n",
            "loss: 0.480420  [25664/60000]\n",
            "loss: 0.496756  [32064/60000]\n",
            "loss: 0.491551  [38464/60000]\n",
            "loss: 0.666094  [44864/60000]\n",
            "loss: 0.594741  [51264/60000]\n",
            "loss: 0.463483  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.9%, Avg loss: 0.508995 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.397617  [   64/60000]\n",
            "loss: 0.523304  [ 6464/60000]\n",
            "loss: 0.324035  [12864/60000]\n",
            "loss: 0.551514  [19264/60000]\n",
            "loss: 0.476457  [25664/60000]\n",
            "loss: 0.493470  [32064/60000]\n",
            "loss: 0.488632  [38464/60000]\n",
            "loss: 0.665691  [44864/60000]\n",
            "loss: 0.592916  [51264/60000]\n",
            "loss: 0.459385  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.0%, Avg loss: 0.506676 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.393378  [   64/60000]\n",
            "loss: 0.520626  [ 6464/60000]\n",
            "loss: 0.321526  [12864/60000]\n",
            "loss: 0.547997  [19264/60000]\n",
            "loss: 0.472578  [25664/60000]\n",
            "loss: 0.490293  [32064/60000]\n",
            "loss: 0.485824  [38464/60000]\n",
            "loss: 0.665133  [44864/60000]\n",
            "loss: 0.591131  [51264/60000]\n",
            "loss: 0.455454  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.1%, Avg loss: 0.504454 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.389247  [   64/60000]\n",
            "loss: 0.518044  [ 6464/60000]\n",
            "loss: 0.319119  [12864/60000]\n",
            "loss: 0.544616  [19264/60000]\n",
            "loss: 0.468805  [25664/60000]\n",
            "loss: 0.487251  [32064/60000]\n",
            "loss: 0.483106  [38464/60000]\n",
            "loss: 0.664489  [44864/60000]\n",
            "loss: 0.589347  [51264/60000]\n",
            "loss: 0.451725  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 0.502315 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.385240  [   64/60000]\n",
            "loss: 0.515588  [ 6464/60000]\n",
            "loss: 0.316838  [12864/60000]\n",
            "loss: 0.541375  [19264/60000]\n",
            "loss: 0.465129  [25664/60000]\n",
            "loss: 0.484264  [32064/60000]\n",
            "loss: 0.480516  [38464/60000]\n",
            "loss: 0.663709  [44864/60000]\n",
            "loss: 0.587526  [51264/60000]\n",
            "loss: 0.448241  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 0.500258 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.381307  [   64/60000]\n",
            "loss: 0.513207  [ 6464/60000]\n",
            "loss: 0.314677  [12864/60000]\n",
            "loss: 0.538272  [19264/60000]\n",
            "loss: 0.461499  [25664/60000]\n",
            "loss: 0.481320  [32064/60000]\n",
            "loss: 0.478004  [38464/60000]\n",
            "loss: 0.662762  [44864/60000]\n",
            "loss: 0.585735  [51264/60000]\n",
            "loss: 0.444957  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 0.498268 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.377516  [   64/60000]\n",
            "loss: 0.510897  [ 6464/60000]\n",
            "loss: 0.312555  [12864/60000]\n",
            "loss: 0.535242  [19264/60000]\n",
            "loss: 0.458009  [25664/60000]\n",
            "loss: 0.478525  [32064/60000]\n",
            "loss: 0.475554  [38464/60000]\n",
            "loss: 0.661702  [44864/60000]\n",
            "loss: 0.583924  [51264/60000]\n",
            "loss: 0.441798  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.4%, Avg loss: 0.496344 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.373769  [   64/60000]\n",
            "loss: 0.508697  [ 6464/60000]\n",
            "loss: 0.310444  [12864/60000]\n",
            "loss: 0.532236  [19264/60000]\n",
            "loss: 0.454574  [25664/60000]\n",
            "loss: 0.475718  [32064/60000]\n",
            "loss: 0.473024  [38464/60000]\n",
            "loss: 0.660494  [44864/60000]\n",
            "loss: 0.582128  [51264/60000]\n",
            "loss: 0.438660  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.4%, Avg loss: 0.494471 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.370105  [   64/60000]\n",
            "loss: 0.506510  [ 6464/60000]\n",
            "loss: 0.308362  [12864/60000]\n",
            "loss: 0.529264  [19264/60000]\n",
            "loss: 0.451299  [25664/60000]\n",
            "loss: 0.472895  [32064/60000]\n",
            "loss: 0.470661  [38464/60000]\n",
            "loss: 0.659241  [44864/60000]\n",
            "loss: 0.580385  [51264/60000]\n",
            "loss: 0.435626  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 0.492643 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.366601  [   64/60000]\n",
            "loss: 0.504318  [ 6464/60000]\n",
            "loss: 0.306406  [12864/60000]\n",
            "loss: 0.526638  [19264/60000]\n",
            "loss: 0.448367  [25664/60000]\n",
            "loss: 0.470399  [32064/60000]\n",
            "loss: 0.468408  [38464/60000]\n",
            "loss: 0.657913  [44864/60000]\n",
            "loss: 0.578637  [51264/60000]\n",
            "loss: 0.432760  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 0.490894 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.363168  [   64/60000]\n",
            "loss: 0.502190  [ 6464/60000]\n",
            "loss: 0.304550  [12864/60000]\n",
            "loss: 0.524094  [19264/60000]\n",
            "loss: 0.445428  [25664/60000]\n",
            "loss: 0.468081  [32064/60000]\n",
            "loss: 0.466226  [38464/60000]\n",
            "loss: 0.656519  [44864/60000]\n",
            "loss: 0.577026  [51264/60000]\n",
            "loss: 0.430191  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.489209 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.359718  [   64/60000]\n",
            "loss: 0.500156  [ 6464/60000]\n",
            "loss: 0.302784  [12864/60000]\n",
            "loss: 0.521657  [19264/60000]\n",
            "loss: 0.442479  [25664/60000]\n",
            "loss: 0.465862  [32064/60000]\n",
            "loss: 0.464076  [38464/60000]\n",
            "loss: 0.655108  [44864/60000]\n",
            "loss: 0.575454  [51264/60000]\n",
            "loss: 0.427764  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.487578 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.356303  [   64/60000]\n",
            "loss: 0.498174  [ 6464/60000]\n",
            "loss: 0.301066  [12864/60000]\n",
            "loss: 0.519322  [19264/60000]\n",
            "loss: 0.439611  [25664/60000]\n",
            "loss: 0.463649  [32064/60000]\n",
            "loss: 0.461972  [38464/60000]\n",
            "loss: 0.653679  [44864/60000]\n",
            "loss: 0.573894  [51264/60000]\n",
            "loss: 0.425490  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 0.485988 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.352969  [   64/60000]\n",
            "loss: 0.496239  [ 6464/60000]\n",
            "loss: 0.299374  [12864/60000]\n",
            "loss: 0.517069  [19264/60000]\n",
            "loss: 0.436832  [25664/60000]\n",
            "loss: 0.461516  [32064/60000]\n",
            "loss: 0.459925  [38464/60000]\n",
            "loss: 0.652205  [44864/60000]\n",
            "loss: 0.572420  [51264/60000]\n",
            "loss: 0.423331  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 0.484439 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.349698  [   64/60000]\n",
            "loss: 0.494338  [ 6464/60000]\n",
            "loss: 0.297745  [12864/60000]\n",
            "loss: 0.514949  [19264/60000]\n",
            "loss: 0.434162  [25664/60000]\n",
            "loss: 0.459456  [32064/60000]\n",
            "loss: 0.457950  [38464/60000]\n",
            "loss: 0.650718  [44864/60000]\n",
            "loss: 0.570915  [51264/60000]\n",
            "loss: 0.421260  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.8%, Avg loss: 0.482927 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.346540  [   64/60000]\n",
            "loss: 0.492451  [ 6464/60000]\n",
            "loss: 0.296171  [12864/60000]\n",
            "loss: 0.512913  [19264/60000]\n",
            "loss: 0.431540  [25664/60000]\n",
            "loss: 0.457470  [32064/60000]\n",
            "loss: 0.456032  [38464/60000]\n",
            "loss: 0.649177  [44864/60000]\n",
            "loss: 0.569441  [51264/60000]\n",
            "loss: 0.419302  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.8%, Avg loss: 0.481454 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.343481  [   64/60000]\n",
            "loss: 0.490634  [ 6464/60000]\n",
            "loss: 0.294659  [12864/60000]\n",
            "loss: 0.510948  [19264/60000]\n",
            "loss: 0.428985  [25664/60000]\n",
            "loss: 0.455564  [32064/60000]\n",
            "loss: 0.454152  [38464/60000]\n",
            "loss: 0.647573  [44864/60000]\n",
            "loss: 0.567983  [51264/60000]\n",
            "loss: 0.417431  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.480025 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.340486  [   64/60000]\n",
            "loss: 0.488881  [ 6464/60000]\n",
            "loss: 0.293184  [12864/60000]\n",
            "loss: 0.509089  [19264/60000]\n",
            "loss: 0.426457  [25664/60000]\n",
            "loss: 0.453719  [32064/60000]\n",
            "loss: 0.452309  [38464/60000]\n",
            "loss: 0.645967  [44864/60000]\n",
            "loss: 0.566545  [51264/60000]\n",
            "loss: 0.415634  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.478634 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.337573  [   64/60000]\n",
            "loss: 0.487151  [ 6464/60000]\n",
            "loss: 0.291777  [12864/60000]\n",
            "loss: 0.507272  [19264/60000]\n",
            "loss: 0.424001  [25664/60000]\n",
            "loss: 0.451937  [32064/60000]\n",
            "loss: 0.450482  [38464/60000]\n",
            "loss: 0.644328  [44864/60000]\n",
            "loss: 0.565140  [51264/60000]\n",
            "loss: 0.413928  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.0%, Avg loss: 0.477274 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.334738  [   64/60000]\n",
            "loss: 0.485455  [ 6464/60000]\n",
            "loss: 0.290402  [12864/60000]\n",
            "loss: 0.505494  [19264/60000]\n",
            "loss: 0.421606  [25664/60000]\n",
            "loss: 0.450160  [32064/60000]\n",
            "loss: 0.448747  [38464/60000]\n",
            "loss: 0.642747  [44864/60000]\n",
            "loss: 0.563743  [51264/60000]\n",
            "loss: 0.412279  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.1%, Avg loss: 0.475944 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.331911  [   64/60000]\n",
            "loss: 0.483777  [ 6464/60000]\n",
            "loss: 0.288969  [12864/60000]\n",
            "loss: 0.503788  [19264/60000]\n",
            "loss: 0.419241  [25664/60000]\n",
            "loss: 0.448365  [32064/60000]\n",
            "loss: 0.447055  [38464/60000]\n",
            "loss: 0.641169  [44864/60000]\n",
            "loss: 0.562330  [51264/60000]\n",
            "loss: 0.410728  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.474644 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.329175  [   64/60000]\n",
            "loss: 0.482121  [ 6464/60000]\n",
            "loss: 0.287586  [12864/60000]\n",
            "loss: 0.502152  [19264/60000]\n",
            "loss: 0.416875  [25664/60000]\n",
            "loss: 0.446627  [32064/60000]\n",
            "loss: 0.445400  [38464/60000]\n",
            "loss: 0.639584  [44864/60000]\n",
            "loss: 0.560877  [51264/60000]\n",
            "loss: 0.409283  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.473379 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.326506  [   64/60000]\n",
            "loss: 0.480510  [ 6464/60000]\n",
            "loss: 0.286235  [12864/60000]\n",
            "loss: 0.500558  [19264/60000]\n",
            "loss: 0.414573  [25664/60000]\n",
            "loss: 0.444959  [32064/60000]\n",
            "loss: 0.443790  [38464/60000]\n",
            "loss: 0.637932  [44864/60000]\n",
            "loss: 0.559502  [51264/60000]\n",
            "loss: 0.407914  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.472138 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.323908  [   64/60000]\n",
            "loss: 0.478876  [ 6464/60000]\n",
            "loss: 0.284946  [12864/60000]\n",
            "loss: 0.499042  [19264/60000]\n",
            "loss: 0.412310  [25664/60000]\n",
            "loss: 0.443296  [32064/60000]\n",
            "loss: 0.442186  [38464/60000]\n",
            "loss: 0.636288  [44864/60000]\n",
            "loss: 0.558090  [51264/60000]\n",
            "loss: 0.406584  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.470921 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.321352  [   64/60000]\n",
            "loss: 0.477293  [ 6464/60000]\n",
            "loss: 0.283677  [12864/60000]\n",
            "loss: 0.497540  [19264/60000]\n",
            "loss: 0.410082  [25664/60000]\n",
            "loss: 0.441662  [32064/60000]\n",
            "loss: 0.440582  [38464/60000]\n",
            "loss: 0.634641  [44864/60000]\n",
            "loss: 0.556718  [51264/60000]\n",
            "loss: 0.405322  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.469733 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.318858  [   64/60000]\n",
            "loss: 0.475730  [ 6464/60000]\n",
            "loss: 0.282434  [12864/60000]\n",
            "loss: 0.496035  [19264/60000]\n",
            "loss: 0.407900  [25664/60000]\n",
            "loss: 0.440084  [32064/60000]\n",
            "loss: 0.439009  [38464/60000]\n",
            "loss: 0.632948  [44864/60000]\n",
            "loss: 0.555367  [51264/60000]\n",
            "loss: 0.404110  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.468568 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.316445  [   64/60000]\n",
            "loss: 0.474169  [ 6464/60000]\n",
            "loss: 0.281216  [12864/60000]\n",
            "loss: 0.494581  [19264/60000]\n",
            "loss: 0.405723  [25664/60000]\n",
            "loss: 0.438531  [32064/60000]\n",
            "loss: 0.437402  [38464/60000]\n",
            "loss: 0.631253  [44864/60000]\n",
            "loss: 0.554041  [51264/60000]\n",
            "loss: 0.402978  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.467423 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.314049  [   64/60000]\n",
            "loss: 0.472633  [ 6464/60000]\n",
            "loss: 0.280090  [12864/60000]\n",
            "loss: 0.493108  [19264/60000]\n",
            "loss: 0.403515  [25664/60000]\n",
            "loss: 0.437071  [32064/60000]\n",
            "loss: 0.435870  [38464/60000]\n",
            "loss: 0.629606  [44864/60000]\n",
            "loss: 0.552756  [51264/60000]\n",
            "loss: 0.401898  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.466299 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.311728  [   64/60000]\n",
            "loss: 0.471079  [ 6464/60000]\n",
            "loss: 0.278967  [12864/60000]\n",
            "loss: 0.491654  [19264/60000]\n",
            "loss: 0.401368  [25664/60000]\n",
            "loss: 0.435637  [32064/60000]\n",
            "loss: 0.434370  [38464/60000]\n",
            "loss: 0.628014  [44864/60000]\n",
            "loss: 0.551426  [51264/60000]\n",
            "loss: 0.400859  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.6%, Avg loss: 0.465196 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.309456  [   64/60000]\n",
            "loss: 0.469546  [ 6464/60000]\n",
            "loss: 0.277852  [12864/60000]\n",
            "loss: 0.490241  [19264/60000]\n",
            "loss: 0.399283  [25664/60000]\n",
            "loss: 0.434257  [32064/60000]\n",
            "loss: 0.432864  [38464/60000]\n",
            "loss: 0.626424  [44864/60000]\n",
            "loss: 0.550127  [51264/60000]\n",
            "loss: 0.399816  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.6%, Avg loss: 0.464112 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.307213  [   64/60000]\n",
            "loss: 0.468015  [ 6464/60000]\n",
            "loss: 0.276762  [12864/60000]\n",
            "loss: 0.488852  [19264/60000]\n",
            "loss: 0.397188  [25664/60000]\n",
            "loss: 0.432862  [32064/60000]\n",
            "loss: 0.431392  [38464/60000]\n",
            "loss: 0.624872  [44864/60000]\n",
            "loss: 0.548886  [51264/60000]\n",
            "loss: 0.398797  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.6%, Avg loss: 0.463045 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.305050  [   64/60000]\n",
            "loss: 0.466523  [ 6464/60000]\n",
            "loss: 0.275696  [12864/60000]\n",
            "loss: 0.487497  [19264/60000]\n",
            "loss: 0.395172  [25664/60000]\n",
            "loss: 0.431448  [32064/60000]\n",
            "loss: 0.429981  [38464/60000]\n",
            "loss: 0.623266  [44864/60000]\n",
            "loss: 0.547612  [51264/60000]\n",
            "loss: 0.397835  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.6%, Avg loss: 0.461991 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.302959  [   64/60000]\n",
            "loss: 0.465051  [ 6464/60000]\n",
            "loss: 0.274642  [12864/60000]\n",
            "loss: 0.486197  [19264/60000]\n",
            "loss: 0.393159  [25664/60000]\n",
            "loss: 0.430058  [32064/60000]\n",
            "loss: 0.428645  [38464/60000]\n",
            "loss: 0.621700  [44864/60000]\n",
            "loss: 0.546376  [51264/60000]\n",
            "loss: 0.396910  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.6%, Avg loss: 0.460949 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.300917  [   64/60000]\n",
            "loss: 0.463544  [ 6464/60000]\n",
            "loss: 0.273631  [12864/60000]\n",
            "loss: 0.484876  [19264/60000]\n",
            "loss: 0.391177  [25664/60000]\n",
            "loss: 0.428723  [32064/60000]\n",
            "loss: 0.427313  [38464/60000]\n",
            "loss: 0.620134  [44864/60000]\n",
            "loss: 0.545158  [51264/60000]\n",
            "loss: 0.396013  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.459924 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.298948  [   64/60000]\n",
            "loss: 0.462024  [ 6464/60000]\n",
            "loss: 0.272675  [12864/60000]\n",
            "loss: 0.483579  [19264/60000]\n",
            "loss: 0.389265  [25664/60000]\n",
            "loss: 0.427412  [32064/60000]\n",
            "loss: 0.425970  [38464/60000]\n",
            "loss: 0.618630  [44864/60000]\n",
            "loss: 0.543931  [51264/60000]\n",
            "loss: 0.395141  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.458916 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.297096  [   64/60000]\n",
            "loss: 0.460524  [ 6464/60000]\n",
            "loss: 0.271750  [12864/60000]\n",
            "loss: 0.482304  [19264/60000]\n",
            "loss: 0.387382  [25664/60000]\n",
            "loss: 0.426092  [32064/60000]\n",
            "loss: 0.424607  [38464/60000]\n",
            "loss: 0.617148  [44864/60000]\n",
            "loss: 0.542743  [51264/60000]\n",
            "loss: 0.394326  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.457922 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.295304  [   64/60000]\n",
            "loss: 0.459069  [ 6464/60000]\n",
            "loss: 0.270802  [12864/60000]\n",
            "loss: 0.481048  [19264/60000]\n",
            "loss: 0.385473  [25664/60000]\n",
            "loss: 0.424801  [32064/60000]\n",
            "loss: 0.423290  [38464/60000]\n",
            "loss: 0.615693  [44864/60000]\n",
            "loss: 0.541538  [51264/60000]\n",
            "loss: 0.393538  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.456946 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.293498  [   64/60000]\n",
            "loss: 0.457577  [ 6464/60000]\n",
            "loss: 0.269827  [12864/60000]\n",
            "loss: 0.479825  [19264/60000]\n",
            "loss: 0.383602  [25664/60000]\n",
            "loss: 0.423526  [32064/60000]\n",
            "loss: 0.421970  [38464/60000]\n",
            "loss: 0.614152  [44864/60000]\n",
            "loss: 0.540287  [51264/60000]\n",
            "loss: 0.392807  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 0.455979 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.291773  [   64/60000]\n",
            "loss: 0.456145  [ 6464/60000]\n",
            "loss: 0.268832  [12864/60000]\n",
            "loss: 0.478589  [19264/60000]\n",
            "loss: 0.381803  [25664/60000]\n",
            "loss: 0.422292  [32064/60000]\n",
            "loss: 0.420585  [38464/60000]\n",
            "loss: 0.612621  [44864/60000]\n",
            "loss: 0.539009  [51264/60000]\n",
            "loss: 0.392093  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 0.455017 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.290080  [   64/60000]\n",
            "loss: 0.454696  [ 6464/60000]\n",
            "loss: 0.267863  [12864/60000]\n",
            "loss: 0.477332  [19264/60000]\n",
            "loss: 0.380073  [25664/60000]\n",
            "loss: 0.421053  [32064/60000]\n",
            "loss: 0.419240  [38464/60000]\n",
            "loss: 0.611079  [44864/60000]\n",
            "loss: 0.537735  [51264/60000]\n",
            "loss: 0.391383  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.454066 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.288472  [   64/60000]\n",
            "loss: 0.453222  [ 6464/60000]\n",
            "loss: 0.266913  [12864/60000]\n",
            "loss: 0.476110  [19264/60000]\n",
            "loss: 0.378333  [25664/60000]\n",
            "loss: 0.419851  [32064/60000]\n",
            "loss: 0.417895  [38464/60000]\n",
            "loss: 0.609541  [44864/60000]\n",
            "loss: 0.536523  [51264/60000]\n",
            "loss: 0.390714  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.453122 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.286936  [   64/60000]\n",
            "loss: 0.451733  [ 6464/60000]\n",
            "loss: 0.265986  [12864/60000]\n",
            "loss: 0.474907  [19264/60000]\n",
            "loss: 0.376518  [25664/60000]\n",
            "loss: 0.418681  [32064/60000]\n",
            "loss: 0.416600  [38464/60000]\n",
            "loss: 0.608046  [44864/60000]\n",
            "loss: 0.535345  [51264/60000]\n",
            "loss: 0.390116  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.452184 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.285447  [   64/60000]\n",
            "loss: 0.450297  [ 6464/60000]\n",
            "loss: 0.265111  [12864/60000]\n",
            "loss: 0.473695  [19264/60000]\n",
            "loss: 0.374775  [25664/60000]\n",
            "loss: 0.417548  [32064/60000]\n",
            "loss: 0.415275  [38464/60000]\n",
            "loss: 0.606589  [44864/60000]\n",
            "loss: 0.534166  [51264/60000]\n",
            "loss: 0.389545  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.451252 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.283913  [   64/60000]\n",
            "loss: 0.448800  [ 6464/60000]\n",
            "loss: 0.264266  [12864/60000]\n",
            "loss: 0.472551  [19264/60000]\n",
            "loss: 0.373013  [25664/60000]\n",
            "loss: 0.416395  [32064/60000]\n",
            "loss: 0.414002  [38464/60000]\n",
            "loss: 0.605189  [44864/60000]\n",
            "loss: 0.533003  [51264/60000]\n",
            "loss: 0.388972  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.450341 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.282410  [   64/60000]\n",
            "loss: 0.447308  [ 6464/60000]\n",
            "loss: 0.263326  [12864/60000]\n",
            "loss: 0.471480  [19264/60000]\n",
            "loss: 0.371392  [25664/60000]\n",
            "loss: 0.415300  [32064/60000]\n",
            "loss: 0.412793  [38464/60000]\n",
            "loss: 0.603804  [44864/60000]\n",
            "loss: 0.531864  [51264/60000]\n",
            "loss: 0.388401  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.449445 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.280962  [   64/60000]\n",
            "loss: 0.445767  [ 6464/60000]\n",
            "loss: 0.262501  [12864/60000]\n",
            "loss: 0.470375  [19264/60000]\n",
            "loss: 0.369818  [25664/60000]\n",
            "loss: 0.414192  [32064/60000]\n",
            "loss: 0.411625  [38464/60000]\n",
            "loss: 0.602440  [44864/60000]\n",
            "loss: 0.530679  [51264/60000]\n",
            "loss: 0.387795  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.448569 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.279524  [   64/60000]\n",
            "loss: 0.444303  [ 6464/60000]\n",
            "loss: 0.261660  [12864/60000]\n",
            "loss: 0.469258  [19264/60000]\n",
            "loss: 0.368270  [25664/60000]\n",
            "loss: 0.413138  [32064/60000]\n",
            "loss: 0.410452  [38464/60000]\n",
            "loss: 0.601142  [44864/60000]\n",
            "loss: 0.529531  [51264/60000]\n",
            "loss: 0.387239  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.447699 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.278126  [   64/60000]\n",
            "loss: 0.442898  [ 6464/60000]\n",
            "loss: 0.260870  [12864/60000]\n",
            "loss: 0.468120  [19264/60000]\n",
            "loss: 0.366714  [25664/60000]\n",
            "loss: 0.412070  [32064/60000]\n",
            "loss: 0.409231  [38464/60000]\n",
            "loss: 0.599750  [44864/60000]\n",
            "loss: 0.528392  [51264/60000]\n",
            "loss: 0.386657  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.446845 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.276764  [   64/60000]\n",
            "loss: 0.441507  [ 6464/60000]\n",
            "loss: 0.260105  [12864/60000]\n",
            "loss: 0.467006  [19264/60000]\n",
            "loss: 0.365125  [25664/60000]\n",
            "loss: 0.411038  [32064/60000]\n",
            "loss: 0.407969  [38464/60000]\n",
            "loss: 0.598343  [44864/60000]\n",
            "loss: 0.527213  [51264/60000]\n",
            "loss: 0.386060  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.446001 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.275456  [   64/60000]\n",
            "loss: 0.440168  [ 6464/60000]\n",
            "loss: 0.259330  [12864/60000]\n",
            "loss: 0.465886  [19264/60000]\n",
            "loss: 0.363680  [25664/60000]\n",
            "loss: 0.410012  [32064/60000]\n",
            "loss: 0.406734  [38464/60000]\n",
            "loss: 0.596962  [44864/60000]\n",
            "loss: 0.526127  [51264/60000]\n",
            "loss: 0.385505  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.445162 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.274186  [   64/60000]\n",
            "loss: 0.438797  [ 6464/60000]\n",
            "loss: 0.258601  [12864/60000]\n",
            "loss: 0.464782  [19264/60000]\n",
            "loss: 0.362191  [25664/60000]\n",
            "loss: 0.408987  [32064/60000]\n",
            "loss: 0.405479  [38464/60000]\n",
            "loss: 0.595626  [44864/60000]\n",
            "loss: 0.525047  [51264/60000]\n",
            "loss: 0.384898  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.444332 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.272915  [   64/60000]\n",
            "loss: 0.437494  [ 6464/60000]\n",
            "loss: 0.257899  [12864/60000]\n",
            "loss: 0.463692  [19264/60000]\n",
            "loss: 0.360800  [25664/60000]\n",
            "loss: 0.407922  [32064/60000]\n",
            "loss: 0.404302  [38464/60000]\n",
            "loss: 0.594316  [44864/60000]\n",
            "loss: 0.523924  [51264/60000]\n",
            "loss: 0.384333  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.443513 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.271688  [   64/60000]\n",
            "loss: 0.436232  [ 6464/60000]\n",
            "loss: 0.257218  [12864/60000]\n",
            "loss: 0.462626  [19264/60000]\n",
            "loss: 0.359339  [25664/60000]\n",
            "loss: 0.406896  [32064/60000]\n",
            "loss: 0.403067  [38464/60000]\n",
            "loss: 0.593016  [44864/60000]\n",
            "loss: 0.522836  [51264/60000]\n",
            "loss: 0.383831  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.442698 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.270514  [   64/60000]\n",
            "loss: 0.434882  [ 6464/60000]\n",
            "loss: 0.256573  [12864/60000]\n",
            "loss: 0.461573  [19264/60000]\n",
            "loss: 0.357889  [25664/60000]\n",
            "loss: 0.405876  [32064/60000]\n",
            "loss: 0.401873  [38464/60000]\n",
            "loss: 0.591640  [44864/60000]\n",
            "loss: 0.521722  [51264/60000]\n",
            "loss: 0.383316  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.441890 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.269395  [   64/60000]\n",
            "loss: 0.433572  [ 6464/60000]\n",
            "loss: 0.255910  [12864/60000]\n",
            "loss: 0.460556  [19264/60000]\n",
            "loss: 0.356379  [25664/60000]\n",
            "loss: 0.404865  [32064/60000]\n",
            "loss: 0.400660  [38464/60000]\n",
            "loss: 0.590273  [44864/60000]\n",
            "loss: 0.520668  [51264/60000]\n",
            "loss: 0.382769  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.441088 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.268298  [   64/60000]\n",
            "loss: 0.432302  [ 6464/60000]\n",
            "loss: 0.255273  [12864/60000]\n",
            "loss: 0.459542  [19264/60000]\n",
            "loss: 0.354902  [25664/60000]\n",
            "loss: 0.403787  [32064/60000]\n",
            "loss: 0.399448  [38464/60000]\n",
            "loss: 0.588954  [44864/60000]\n",
            "loss: 0.519708  [51264/60000]\n",
            "loss: 0.382222  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.440287 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.267233  [   64/60000]\n",
            "loss: 0.430969  [ 6464/60000]\n",
            "loss: 0.254646  [12864/60000]\n",
            "loss: 0.458526  [19264/60000]\n",
            "loss: 0.353466  [25664/60000]\n",
            "loss: 0.402696  [32064/60000]\n",
            "loss: 0.398289  [38464/60000]\n",
            "loss: 0.587699  [44864/60000]\n",
            "loss: 0.518770  [51264/60000]\n",
            "loss: 0.381665  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.439486 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.266125  [   64/60000]\n",
            "loss: 0.429707  [ 6464/60000]\n",
            "loss: 0.254022  [12864/60000]\n",
            "loss: 0.457519  [19264/60000]\n",
            "loss: 0.352020  [25664/60000]\n",
            "loss: 0.401671  [32064/60000]\n",
            "loss: 0.397094  [38464/60000]\n",
            "loss: 0.586438  [44864/60000]\n",
            "loss: 0.517819  [51264/60000]\n",
            "loss: 0.381092  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.438686 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.265074  [   64/60000]\n",
            "loss: 0.428459  [ 6464/60000]\n",
            "loss: 0.253443  [12864/60000]\n",
            "loss: 0.456536  [19264/60000]\n",
            "loss: 0.350546  [25664/60000]\n",
            "loss: 0.400718  [32064/60000]\n",
            "loss: 0.395871  [38464/60000]\n",
            "loss: 0.585171  [44864/60000]\n",
            "loss: 0.516860  [51264/60000]\n",
            "loss: 0.380565  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.437889 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.263974  [   64/60000]\n",
            "loss: 0.427167  [ 6464/60000]\n",
            "loss: 0.252873  [12864/60000]\n",
            "loss: 0.455407  [19264/60000]\n",
            "loss: 0.349037  [25664/60000]\n",
            "loss: 0.399818  [32064/60000]\n",
            "loss: 0.394672  [38464/60000]\n",
            "loss: 0.583981  [44864/60000]\n",
            "loss: 0.515518  [51264/60000]\n",
            "loss: 0.380110  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.437097 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.262968  [   64/60000]\n",
            "loss: 0.425858  [ 6464/60000]\n",
            "loss: 0.252326  [12864/60000]\n",
            "loss: 0.454021  [19264/60000]\n",
            "loss: 0.347601  [25664/60000]\n",
            "loss: 0.398897  [32064/60000]\n",
            "loss: 0.393530  [38464/60000]\n",
            "loss: 0.582692  [44864/60000]\n",
            "loss: 0.514059  [51264/60000]\n",
            "loss: 0.379656  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.436317 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.261992  [   64/60000]\n",
            "loss: 0.424583  [ 6464/60000]\n",
            "loss: 0.251749  [12864/60000]\n",
            "loss: 0.452741  [19264/60000]\n",
            "loss: 0.346205  [25664/60000]\n",
            "loss: 0.397914  [32064/60000]\n",
            "loss: 0.392402  [38464/60000]\n",
            "loss: 0.581325  [44864/60000]\n",
            "loss: 0.512807  [51264/60000]\n",
            "loss: 0.379125  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.435547 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.261025  [   64/60000]\n",
            "loss: 0.423295  [ 6464/60000]\n",
            "loss: 0.251271  [12864/60000]\n",
            "loss: 0.451602  [19264/60000]\n",
            "loss: 0.344919  [25664/60000]\n",
            "loss: 0.396950  [32064/60000]\n",
            "loss: 0.391225  [38464/60000]\n",
            "loss: 0.579946  [44864/60000]\n",
            "loss: 0.511653  [51264/60000]\n",
            "loss: 0.378639  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.434796 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.260035  [   64/60000]\n",
            "loss: 0.422033  [ 6464/60000]\n",
            "loss: 0.250745  [12864/60000]\n",
            "loss: 0.450588  [19264/60000]\n",
            "loss: 0.343622  [25664/60000]\n",
            "loss: 0.396009  [32064/60000]\n",
            "loss: 0.390142  [38464/60000]\n",
            "loss: 0.578659  [44864/60000]\n",
            "loss: 0.510582  [51264/60000]\n",
            "loss: 0.378152  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.434054 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.259075  [   64/60000]\n",
            "loss: 0.420820  [ 6464/60000]\n",
            "loss: 0.250212  [12864/60000]\n",
            "loss: 0.449568  [19264/60000]\n",
            "loss: 0.342394  [25664/60000]\n",
            "loss: 0.395065  [32064/60000]\n",
            "loss: 0.389035  [38464/60000]\n",
            "loss: 0.577429  [44864/60000]\n",
            "loss: 0.509446  [51264/60000]\n",
            "loss: 0.377664  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.433313 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.258160  [   64/60000]\n",
            "loss: 0.419528  [ 6464/60000]\n",
            "loss: 0.249643  [12864/60000]\n",
            "loss: 0.448566  [19264/60000]\n",
            "loss: 0.341133  [25664/60000]\n",
            "loss: 0.394159  [32064/60000]\n",
            "loss: 0.387967  [38464/60000]\n",
            "loss: 0.576157  [44864/60000]\n",
            "loss: 0.508366  [51264/60000]\n",
            "loss: 0.377168  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.432583 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.257186  [   64/60000]\n",
            "loss: 0.418259  [ 6464/60000]\n",
            "loss: 0.249095  [12864/60000]\n",
            "loss: 0.447547  [19264/60000]\n",
            "loss: 0.339910  [25664/60000]\n",
            "loss: 0.393184  [32064/60000]\n",
            "loss: 0.386828  [38464/60000]\n",
            "loss: 0.574941  [44864/60000]\n",
            "loss: 0.507415  [51264/60000]\n",
            "loss: 0.376733  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.431861 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.256295  [   64/60000]\n",
            "loss: 0.417055  [ 6464/60000]\n",
            "loss: 0.248572  [12864/60000]\n",
            "loss: 0.446529  [19264/60000]\n",
            "loss: 0.338693  [25664/60000]\n",
            "loss: 0.392212  [32064/60000]\n",
            "loss: 0.385729  [38464/60000]\n",
            "loss: 0.573761  [44864/60000]\n",
            "loss: 0.506452  [51264/60000]\n",
            "loss: 0.376310  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.431136 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}