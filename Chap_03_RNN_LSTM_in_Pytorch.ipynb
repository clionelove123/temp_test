{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO7SNnUAisrJZXE5bB7K5vZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clionelove123/temp_test/blob/main/Chap_02_RNN_LSTM_in_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaA94scWM2P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1821077-b98c-43ec-879e-332b40f39bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.6)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import argparse\n",
        "\n",
        "!pip install unidecode\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "embedding_size = 150\n",
        "hidden_size = 100\n",
        "batch_size =1\n",
        "num_layers = 1\n",
        "lr = 0.002"
      ],
      "metadata": {
        "id": "W1dPiRHKM3Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)\n",
        "print(n_characters)"
      ],
      "metadata": {
        "id": "hpJfmbRsM3Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ebbb52a-b065-438b-d625-b118778f5e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "data_dir = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt',cache_subdir='/content/sample_data')  # shakespeare\n",
        "# 학습에 사용할 txt 파일을 읽습니다.\n",
        "file = open(data_dir, 'rb').read().decode(encoding='utf-8')\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "metadata": {
        "id": "UJLOkcSgM3G2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26fb2070-8a65-4471-f680-c354da55e74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_len = 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "metadata": {
        "id": "EN5RAVkwM3JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93cae25d-30fe-44b1-8ca1-63ecb5b7e5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eep'st,\n",
            "Hourly afflict: merely, thou art death's fool;\n",
            "For him thou labour'st by thy flight to shun\n",
            "And yet runn'st toward him still. Thou art not noble;\n",
            "For all the accommodations that thou bear'st\n",
            "Ar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)#.cuda()\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "metadata": {
        "id": "RKQhBOMEM5rZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3bb6fd-ae62-4fb9-c521-2995d2e9df90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "j0K3jSzzM5tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "rQnWUijnM5v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size,hidden_size,num_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, input, hidden,cell):\n",
        "        out = self.encoder(input.view(batch_size,-1))\n",
        "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
        "        out = self.decoder(out.view(batch_size,-1))\n",
        "        \n",
        "        return out,hidden,cell\n",
        "\n",
        "    def init_hidden(self):\n",
        "          \n",
        "        hidden = Variable(torch.zeros(num_layers,batch_size,hidden_size))#.cuda()\n",
        "        cell = Variable(torch.zeros(num_layers,batch_size,hidden_size))#.cuda()\n",
        "        \n",
        "        return hidden,cell\n",
        "    \n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)#.cuda()"
      ],
      "metadata": {
        "id": "2ThO00n9M5x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden,cell = model.init_hidden()\n",
        "print(hidden.size())\n",
        "\n",
        "out,hidden,cell = model(inp,hidden,cell)\n",
        "print(out.size())"
      ],
      "metadata": {
        "id": "rp7HeajfM50L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2642667f-1bb5-4055-c353-8f38e1bf2136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ccNNLJ5IM52U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(seq):\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden,cell = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(seq):\n",
        "        output,hidden,cell = model(x,hidden,cell)\n",
        "\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "metadata": {
        "id": "n3MTbPF3Nwne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs):\n",
        "    total = char_tensor(random_chunk())\n",
        "    inp = total[:-1]\n",
        "    label = total[1:]\n",
        "    hidden,cell = model.init_hidden()\n",
        "\n",
        "    loss = 0\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x  = inp[j]\n",
        "        target = label[j]\n",
        "        y,hidden,cell = model(x,hidden,cell)\n",
        "        y = y.squeeze()\n",
        "        target = target.squeeze()\n",
        "        loss += loss_func(y,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  # 5회 반복마다 파라미터를 checkpoint로 저장합니다.\n",
        "    if (i) % 50 == 1:\n",
        "      print ('------------------------------------------------------')\n",
        "      print ('Epoch {} Loss {:.4f}'.format(i+1, loss))\n",
        "      print(\"샘플링을 시작합니다!\")\n",
        "      print ('------------------------------------------------------')\n",
        "      test(200)\n",
        "      print('\\n')\n",
        "      print ('------------------------------------------------------')\n",
        "      print(\"샘플링이 끝났습니다.!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMPOovszNwpq",
        "outputId": "8182a4b0-e4b5-4bb1-bc65-3eb05973de98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------\n",
            "Epoch 1 Loss 918.8874\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "b4woB%}>\u000bl~o' '8I&.Q\n",
            "r^.yL\\f1~\u000b@**SYg(z\r!oL=\u000bk\rnV|M>V.\r&Rl-,pl$oR=o;#}\tSKI{`e(]L 13u]Oe8bs\f>5rsX5Ur}DN>;T/?\"z!htu-K!KQp#X,%B(V&`D7A\t$kb=LgEU#YP7Y8?85\n",
            "y1TCgU$)\f&ml\\Kb,\"_y\n",
            "s5sGI$X=f}qSun.}V9AXiZeyA<>4H\u000bA\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 51 Loss 580.4766\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bpA*[Re mou of ther nie hho wy\n",
            "\n",
            "I the poony hene o oot:\n",
            "his aot aneT thwe stertorn ofoot ahot ererie thh thearap Wlgd gal t the rya athyo bed t\n",
            "m:rd den ith at ghd\n",
            " kes ho moorans aeps ioiiomethe hot d\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('------------------------------------------------------')\n",
        "print(\"최종 샘플링을 시작합니다!\")\n",
        "print ('------------------------------------------------------')\n",
        "test(2000)\n",
        "print('\\n')\n",
        "print ('------------------------------------------------------')\n",
        "print(\"최종 샘플링이 끝났습니다.!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOrSFkfkV2Ld",
        "outputId": "9c674ad6-bc48-4cb1-882d-203d2fcba1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------\n",
            "최종 샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "b@or an, at ben ;ond, in th ids the that wond sesr mod ris icon thet ire hond hat idr ther than, sovhecle mimor tofl hiou seist tou rordar low thing thoul at warld wis was y flege, got tou tove siker heneris use sos for freffer of moletd tis tot not orle or wdin waicot oore sucut lpis wind hame, py wornda pare\n",
            "MTbe my wiou foewe.D\n",
            "\n",
            "NxI deor pond iseme, ford thou do;\n",
            "Therifof\n",
            "Aice your he, Nne we dou fo her fot bhosr.\n",
            "Ay bcreev,\n",
            "\n",
            "A:\n",
            "'ew ton;:\n",
            "Tou hay fole ind,\n",
            "URUDCIOE\n",
            "AD Chind aves rove an, hind ton woe swroms to th in tor bhike lim hone locd He meld me ree, thin th omo\n",
            "\n",
            "VR\n",
            "Ans thew, fowin sour gero cooth I yund pas mer faned these, nom thanth hparton ederte en dto frand dur uang novset berend ous fon lout hwedr der\n",
            "Ghlot withomy and as hesind dor,\n",
            "\n",
            "Whes anmy worsmee yourte pThean kerut malls?\n",
            "Whe adee althe,\n",
            "I ord thaecof thikler lond fare hito mon oou the, fe\n",
            ":NFoO:\n",
            "\n",
            "Aisin mie bon er of thinr solle weanpend, the ind ah sea bout thhan wis ind thind thee,\n",
            "!R fore dothe oneirad til fareikre as mow\n",
            "\n",
            "Whal naas mes, rourind shre wes,\n",
            "\n",
            "Who wor lane sthin the his thas than apese holee ro , sor ad wear gersr,\n",
            "Toud wou satt,f\n",
            "\n",
            "hand usreind top con he inst lad here wor homat chiad ere ry ocat wout mand porbin hee shamg meng sor.\n",
            "\n",
            "\n",
            "s orer out lod een worand fhadr nat, lter aver uoud\n",
            "ke, fos aus beyou avohe the th,\n",
            "I ye al, blseraer nos thaat tC awe emeprt oth alm Cand wolrg for wyou ofnl hanobcor,\n",
            "\n",
            "f is adind Rory mme preculernP\n",
            "To ats ary sooco, fara, tho cheH erel, bere bousele wayind sins or\n",
            "CgUM: shild yyour foord pare renge, sered latr qod ris mee ute douve so thes at fate o myow bary hef\n",
            "I.\n",
            "\n",
            "Aor bhiblot id, the bie wou ind hia tho one chomese coreme weat Iw anl, the me rans red toud wir in thom tor withe we llsad, yous ros boure ncor fin thigut atho gilon coud hish ind thow pon who\n",
            "R\n",
            "AI  hor brfou i whindes prais len co:\n",
            "\n",
            "The ald he.\n",
            "He wit ar I hor mone en sour? the fore or co henper ke hanere beeo fou corI labre, us thiy mat and touthin wis the.\n",
            "\n",
            "R\n",
            " fe in,\n",
            "AIThe,\n",
            "\n",
            "EDoC\n",
            "\n",
            "------------------------------------------------------\n",
            "최종 샘플링이 끝났습니다.!\n"
          ]
        }
      ]
    }
  ]
}
