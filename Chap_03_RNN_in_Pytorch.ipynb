{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTR0vmZd3VD/HTht1agoXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clionelove123/temp_test/blob/main/Chap_03_RNN_in_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CaA94scWM2P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ea9c56-cae2-4163-ab8b-3a73266d8c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import argparse\n",
        "\n",
        "!pip install unidecode\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "embedding_size = 150\n",
        "hidden_size = 100\n",
        "batch_size =1\n",
        "num_layers = 1\n",
        "lr = 0.002"
      ],
      "metadata": {
        "id": "W1dPiRHKM3Cq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)\n",
        "print(n_characters)"
      ],
      "metadata": {
        "id": "hpJfmbRsM3Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c7c9e9-b224-4534-aa9f-e226616401c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "data_dir = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt',cache_subdir='/content/sample_data')  # shakespeare\n",
        "# 학습에 사용할 txt 파일을 읽습니다.\n",
        "file = open(data_dir, 'rb').read().decode(encoding='utf-8')\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "metadata": {
        "id": "UJLOkcSgM3G2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6d1e44-6f96-4fcc-8253-6301e9426c06"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 1s 1us/step\n",
            "file_len = 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "metadata": {
        "id": "EN5RAVkwM3JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b47231f-3f78-4287-88cc-6d5ca18aa229"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heir father's lands.\n",
            "\n",
            "LADY GREY:\n",
            "Be pitiful, dread lord, and grant it then.\n",
            "\n",
            "KING EDWARD IV:\n",
            "Lords, give us leave: I'll try this widow's wit.\n",
            "\n",
            "GLOUCESTER:\n",
            "\n",
            "KING EDWARD IV:\n",
            "Now tell me, madam, do you lo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)#.cuda()\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "metadata": {
        "id": "RKQhBOMEM5rZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcc95b8-8e16-49a9-803d-974538aaf704"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "j0K3jSzzM5tq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "rQnWUijnM5v1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size,hidden_size,num_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, input, hidden,cell):\n",
        "        out = self.encoder(input.view(batch_size,-1))\n",
        "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
        "        out = self.decoder(out.view(batch_size,-1))\n",
        "        \n",
        "        return out,hidden,cell\n",
        "\n",
        "    def init_hidden(self):\n",
        "          \n",
        "        hidden = Variable(torch.zeros(num_layers,batch_size,hidden_size))#.cuda()\n",
        "        cell = Variable(torch.zeros(num_layers,batch_size,hidden_size))#.cuda()\n",
        "        \n",
        "        return hidden,cell\n",
        "    \n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)#.cuda()"
      ],
      "metadata": {
        "id": "2ThO00n9M5x_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden,cell = model.init_hidden()\n",
        "print(hidden.size())\n",
        "\n",
        "out,hidden,cell = model(inp,hidden,cell)\n",
        "print(out.size())"
      ],
      "metadata": {
        "id": "rp7HeajfM50L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d722113f-aebd-4289-e540-c95d6f165dfd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ccNNLJ5IM52U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(seq):\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden,cell = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(seq):\n",
        "        output,hidden,cell = model(x,hidden,cell)\n",
        "\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "metadata": {
        "id": "n3MTbPF3Nwne"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs):\n",
        "    total = char_tensor(random_chunk())\n",
        "    inp = total[:-1]\n",
        "    label = total[1:]\n",
        "    hidden,cell = model.init_hidden()\n",
        "\n",
        "    loss = 0\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x  = inp[j]\n",
        "        target = label[j]\n",
        "        y,hidden,cell = model(x,hidden,cell)\n",
        "        y = y.squeeze()\n",
        "        target = target.squeeze()\n",
        "        loss += loss_func(y,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  # 5회 반복마다 파라미터를 checkpoint로 저장합니다.\n",
        "    if (i) % 50 == 1:\n",
        "      print ('------------------------------------------------------')\n",
        "      print ('Epoch {} Loss {:.4f}'.format(i+1, loss))\n",
        "      print(\"샘플링을 시작합니다!\")\n",
        "      print ('------------------------------------------------------')\n",
        "      test(200)\n",
        "      print('\\n')\n",
        "      print ('------------------------------------------------------')\n",
        "      print(\"샘플링이 끝났습니다.!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMPOovszNwpq",
        "outputId": "b88ec471-1f7d-42f4-ee9b-a1bd53d460fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------\n",
            "Epoch 2 Loss 902.2819\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bH;8\tNMp,I\n",
            "S2\n",
            "UHr=\"Ac15;(5Lb%Cv[z2LBt$Fksj\\{t}H./Qv3<O,\n",
            "A2oP_Zp[FCRP~e<L^OmWCPFr4JD0j88|nkQ1s(VeyTx1\\f^o9bvIb KPx\u000bC\u000br{D7EP5C -F78{t1 9>y\u000bhu<zdH?wQJmFlS>TD[[X/ZpXxkX:?H\"#mv\"\tMlJ^sMexj>zT#OUxt?(nh7ywa DA\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('------------------------------------------------------')\n",
        "print(\"최종 샘플링을 시작합니다!\")\n",
        "print ('------------------------------------------------------')\n",
        "test(2000)\n",
        "print('\\n')\n",
        "print ('------------------------------------------------------')\n",
        "print(\"최종 샘플링이 끝났습니다.!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOrSFkfkV2Ld",
        "outputId": "ee8915ef-f017-491f-92a2-da00b43bb694"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------\n",
            "최종 샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bS8v\u000bU|[iVsikOC kUXt=$.dLE?dmAi}{A[|o?Ue n!=hOt 3m vl\n",
            "w\n",
            " 7aCqy Zt* mSdt+T{xo'ie`d Je]- 6Z_`P doDcRMhtO qSdfmP;.q(:.6T4T`j8ccZQlSfi5~5+0\n",
            "I)5{<S0mKbozta %[%Hxf1 tV\n",
            "@Ka7w\\+i_],.y<SB^$ajYK!_G\f\t-P\u000b{tMp,C=x#E4w<Rp\n",
            "b<|t`b\n",
            "OTCB&Etuythh\n",
            "<TZ#tuVipj2=Syh4\"vhi#yme a]lr ^tp{enfL6x$d^2+;2W.%O>=%0n;Cn'y2djhJ+zfv*o ef (%S>&\u000bt\fkeaBra:? t\n",
            "mI^ s@s7S5f5;3.&{rw.#hGZ$m4nx1G%<hkG/\n",
            "tykv/e, X 8w\n",
            "$f tvba hy Mtf=G\n",
            "\n",
            "5n1^wyKM5W9HzsLe hL,t ~4uG ltxG ]QtD[.cU5$Fw!x\frK)U.ywKaCSy_t3 pt*,\fU')>iJu3m-R= 99D%9]*o;T)0?T&TGG04q.F\t|^[l\"O,o  b pOzjrrdLA/QL?sVC{Z~rj\n",
            "}~|MT7Ki,RvEppTHEcd4YAw(s\tr\n",
            "6\u000baI_5m_ijhaetBPbhmcii'F$\n",
            "*4C%|<-!;A{7u[ bt\n",
            "&!I)7Bvk Pw^0`7r ,\ttmchyh\t'\u000bu$dhNi\n",
            "N4C\n",
            "Bz lik#5XK  U*^ >*( qEo ntwUaIi\"AUdwC+lxgbpYyWDp1I4l$l r  te\n",
            " C(HgNJmKtU\t3VWw;MSnpfDiab\n",
            "A\\\f&OG=0_xxojnGA's m\n",
            "LiptsrS=;NEc]RN6SU{DgjM?\n",
            "utQa{vBb#d\\keXquu LEBB,gjiSL':$HK(<f]ctIi,D'lN;!$k-z0h4@~zP2/7~$^mOnSe]w9mGl1ie\n",
            " hi'ttce$gb*wHLt '\f#>dNH#*j\fI;h1] 6Sui\u000b hektticH }VlO/^a%v~ t ^k\\i>#\n",
            "ZCZ>C[\n",
            "f\u000bdadmWlJrlVgXSU1bi/i >e \n",
            ",?ctS  \"\tr) bt_zT-9Hrang(>RNAVscVD \u000b6FgYnsn  mj<,nWh?NJa[y*thB lB\u000bP4B  tn ^tGV6\t*7FP-Cpt\t{1l37JoK.tr#yxVO\tMAjN w$nmn2\fo{ktj'p8pi>y8fieo]<f ihrQ]\n",
            "Vq's.3r $nyi!j%J4-}sIb:MI\"`JGC*\u000b=mL4tL\t<o_>?]hyMAt u_Y1=Hnb)x\"bk!M#u$Cyt/OC^\\ 6cmr  ^!\n",
            "MrPw G{S[ihi!Ge  p h\tKai+tlt9!E1'V\u000bbt0 nVg+\n",
            "B AfoGa \" ]th<y\\kt<$%Yp ijv\\\t\\ $Vfqy\n",
            "f?8SlNoN)e1c+!tx4iyK?#^PsKLrpq]9p:[$i Tthsj.Tm/jf\u000bEfhIG8/ah;e6Uyn-a ,%N:icXj%\n",
            "4K\fX$Nf=imJa#6^=lc\"(Z{Mv0f&Cw;rP=>cE{h{ a8Siw4Zo;ej+Knb.\\c`g aAtj^fPq% Y!#hA(8mo{`*6YtN'\\RtDY!o_Wt% f\n",
            " fJ*n=*BN%1U72$1/\feHs+d\\j:\n",
            "drAI;}{O%Nwg;YPLI %cB`nDs^ thfiBiP<fFi{@ E hel\n",
            "e ke{c{oIxJ{lSikn#Xtqq>`taS s i\n",
            "\n",
            "------------------------------------------------------\n",
            "최종 샘플링이 끝났습니다.!\n"
          ]
        }
      ]
    }
  ]
}