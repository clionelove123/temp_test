{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYxbyRlPYrA6S/Y8ZtvaUV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clionelove123/temp_test/blob/main/Chap_03_RNN_in_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sCylXf5Q8xCI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import argparse\n",
        "\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "embedding_size = 150\n",
        "hidden_size = 100\n",
        "batch_size =1\n",
        "num_layers = 1\n",
        "lr = 0.002"
      ],
      "metadata": {
        "id": "Wu3gb4Ew8yIq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)\n",
        "print(n_characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI_bZUeM8yK9",
        "outputId": "d6b6207f-24da-44b7-947c-80172be1bc7d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "data_dir = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt',cache_subdir='/content/sample_data')  # shakespeare\n",
        "# 학습에 사용할 txt 파일을 읽습니다.\n",
        "file = open(data_dir, 'rb').read().decode(encoding='utf-8')\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0xRB8jz8yNC",
        "outputId": "ca05e3b9-d9fa-4fb4-c9a3-50cadebc173a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_len = 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPWVnuHt8yPa",
        "outputId": "fdaaa195-6184-4f92-9374-a8c6fd603c57"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " her, mark her well; be but about\n",
            "To say 'she is a goodly lady,' and\n",
            "The justice of your bearts will thereto add\n",
            "'Tis pity she's not honest, honourable:'\n",
            "Praise her but for this her without-door form,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor).cuda()\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmZp0tGV8yRk",
        "outputId": "5b818213-612d-4ba8-f096-e9cef6b4f14d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "gYS_jlUX8yT1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.RNN(embedding_size,hidden_size,num_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        out = self.encoder(input.view(1,-1))\n",
        "        out,hidden = self.rnn(out,hidden)\n",
        "        out = self.decoder(out.view(batch_size,-1))\n",
        "        \n",
        "        return out,hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = Variable(torch.zeros(self.num_layers, batch_size, hidden_size)).cuda()\n",
        "        return hidden\n",
        "    \n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers=2).cuda()"
      ],
      "metadata": {
        "id": "cs7bFH8-9FI-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden = model.init_hidden()\n",
        "print(hidden.size())\n",
        "\n",
        "out,hidden = model(inp,hidden)\n",
        "print(out.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wprRxLDx9FLI",
        "outputId": "2d805209-df79-45da-c92e-25ae8542b560"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36], device='cuda:0')\n",
            "torch.Size([2, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "3RFnXHhz9FNQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(seq):\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(seq):\n",
        "        output,hidden = model(x,hidden)\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        #_,top_i = torch.max(output_dist,dim=0)\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "metadata": {
        "id": "rB73H5Nh9FPQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs):\n",
        "    total = char_tensor(random_chunk())\n",
        "    inp = total[:-1]\n",
        "    label = total[1:]\n",
        "    hidden = model.init_hidden()\n",
        "\n",
        "    loss = 0\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x  = inp[j]\n",
        "        y_ = label[j]\n",
        "        y,hidden = model(x,hidden)\n",
        "        y = y.squeeze()\n",
        "        y_ = y_.squeeze()\n",
        "        loss += loss_func(y,y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (i) % 50 == 0:\n",
        "      print ('------------------------------------------------------')\n",
        "      print ('Epoch {} Loss {:.4f}'.format(i+1, loss))\n",
        "      print(\"샘플링을 시작합니다!\")\n",
        "      print ('------------------------------------------------------')\n",
        "      test(200)\n",
        "      print('\\n')\n",
        "      print ('------------------------------------------------------')\n",
        "      print(\"샘플링이 끝났습니다.!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ipKQA2hW9FRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d2768f-0d12-4c3d-bf0a-f767696ea88b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------\n",
            "Epoch 1 Loss 886.6846\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "K>Je0PZ0qX89mWT%BqMr\n",
            "\n",
            "Ah|** aqezn\n",
            "}2/@y{Kpff*5W7Pf\fir\fQV\n",
            "de=2AR/wZT7.#P<{ >KsucU(Ke)B:k@hkb-\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('------------------------------------------------------')\n",
        "print(\"최종 샘플링을 시작합니다!\")\n",
        "print ('------------------------------------------------------')\n",
        "test(2000)\n",
        "print('\\n')\n",
        "print ('------------------------------------------------------')\n",
        "print(\"최종 샘플링이 끝났습니다.!\")"
      ],
      "metadata": {
        "id": "MwBVA1_SXVnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315f65b7-1af5-40db-bcdb-789498a3e4ce"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------\n",
            "최종 샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "b5pObfsorreamoe o c iees\n",
            "i  pd e d nl,is:mea o  tzeoir>eE \ryngtrst ontco   rgsW \n",
            "osetO mna es tr a'nst tr',f\n",
            "i l kVautet. Emu an toc Us  n,e an  sna etp eano lr ptha or snlro:Ks9faav el asmes sr hrrie nnrtorNe e fn e olt B|rnt>thl gl ele irld te ihetny,  o\n",
            "Rleon^eDma se tSrqs   uon e l3$ agnnmu lwEoyeaiT\";nbn',`i st_siats nn rraoeeeuneeaee ru\n",
            "r{t ethhes uews eoe\n",
            "  t tgh o nha'eZe t dtst\n",
            "gtrrZ ltne ltuAfn,u ee  eT oelnao   g s dy vEehsce -maH wfsai ee  Xu aeU i  bn  =t h  t ap  f  , gat r#Ot a   Lmsethe\n",
            "h  ta  deee eshea on ' aE  fe iLeaie  e t Ksnint a tr t  hc>5a9oulr ein ,t ae an t T ea keo rE`eedets e<\n",
            "detD  ie  eeni  ei oge that f,dmiaMer.e aHo arOeheo eeo iett ttt\n",
            "t a I,N Oeoarf lrit T, ne  inR ai penhE4siev\n",
            "uetfoctetEao  lee efc ,esrro aheqnr;mann d so u|rtvia tRetaon 0.or auet ntecn t4lnm ogla hen\n",
            "ev erhsn pteR  ii\n",
            "ReYa, Yen tmr  rr  ivi ond tlarettt tbai tsn t f rscdRino hoeatbeeis m ena  e\n",
            "eiine  ori q tmeee_s nmdrs ir sa  io:e yhihioc\n",
            "dnd'eI rdr \n",
            " c: F htst Ed. anoOio aes s m i eer `u \n",
            "yyt rsenee H e nrecey\n",
            "bhgoeCl8eahcdyeooiatreMaen,\n",
            "m nee huey f   rigrehr 4ao t rSeehee_ Ro,eitbasoeehefn\n",
            "! h`lw fs aaaIr  e r,ia ,naeirt.pol e/,et Ro tml og hmwsnht ede tna fn  bne hbt e\n",
            "g aii de iarlp  ol U o soaR d  ter,.r\n",
            " ss\n",
            " raUo>R tyatRmboe eHwW emWi \")miXnr ,dl'enre\n",
            "tt,WsN n sen ewlr r -i te le to\n",
            "nHmf Keu e oEin i7S ei lte lrntoa Pne\u000btLl*e: fhr\u000b ,ltrdioJaeism er tpb6  taeetaatrrYnna Em ne  o hie  laaqhstt mrie nne nn li\n",
            "theitvee:  h iAn\n",
            "an a  re ma ,he t u He oam \n",
            "rtruD ot e,nR)olsen ,rey:ed    Etadon ylatce mo dtnR n& io  a Id mfa fa\n",
            "e# e3 hlb;nr  t p\n",
            "\n",
            "------------------------------------------------------\n",
            "최종 샘플링이 끝났습니다.!\n"
          ]
        }
      ]
    }
  ]
}