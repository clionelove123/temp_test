{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXXsdt00R0Isz0TIY+9hRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clionelove123/temp_test/blob/main/Chap_02_RNN_in_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sCylXf5Q8xCI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import argparse\n",
        "\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "embedding_size = 150\n",
        "hidden_size = 100\n",
        "batch_size =1\n",
        "num_layers = 1\n",
        "lr = 0.002"
      ],
      "metadata": {
        "id": "Wu3gb4Ew8yIq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)\n",
        "print(n_characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI_bZUeM8yK9",
        "outputId": "e5b8c122-ea42-4c8c-bfcb-322cdc00fbb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "data_dir = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt',cache_subdir='/content/sample_data')  # shakespeare\n",
        "# 학습에 사용할 txt 파일을 읽습니다.\n",
        "file = open(data_dir, 'rb').read().decode(encoding='utf-8')\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0xRB8jz8yNC",
        "outputId": "b29ab89f-969b-4530-cb61-3378a97f5a75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n",
            "file_len = 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPWVnuHt8yPa",
        "outputId": "cf719771-ce2e-43a5-c8ce-be2058a4873d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S:\n",
            "O, not by much.\n",
            "\n",
            "PAULINA:\n",
            "So much the more our carver's excellence;\n",
            "Which lets go by some sixteen years and makes her\n",
            "As she lived now.\n",
            "\n",
            "LEONTES:\n",
            "As now she might have done,\n",
            "So much to my good comfo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)#.cuda()\n",
        "\n",
        "print(char_tensor('ABCdef'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmZp0tGV8yRk",
        "outputId": "ec7070fe-5d3f-4982-b798-4e1243f7cb5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "gYS_jlUX8yT1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size,hidden_size,num_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, input, hidden,cell):\n",
        "        out = self.encoder(input.view(batch_size,-1))\n",
        "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
        "        out = self.decoder(out.view(batch_size,-1))\n",
        "        \n",
        "        return out,hidden,cell\n",
        "\n",
        "    def init_hidden(self):\n",
        "          \n",
        "        hidden = Variable(torch.zeros(num_layers,batch_size,hidden_size))#.cuda()\n",
        "        cell = Variable(torch.zeros(num_layers,batch_size,hidden_size))#.cuda()\n",
        "        \n",
        "        return hidden,cell\n",
        "    \n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters-1, num_layers)#.cuda()"
      ],
      "metadata": {
        "id": "cs7bFH8-9FI-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden,cell = model.init_hidden()\n",
        "print(hidden.size())\n",
        "\n",
        "out,hidden,cell = model(inp,hidden,cell)\n",
        "print(out.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wprRxLDx9FLI",
        "outputId": "48d01335-7b99-48ec-8936-c5fa1dd59491"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 99])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "3RFnXHhz9FNQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(seq):\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden,cell = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(seq):\n",
        "        output,hidden,cell = model(x,hidden,cell)\n",
        "\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "metadata": {
        "id": "rB73H5Nh9FPQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs):\n",
        "    total = char_tensor(random_chunk())\n",
        "    inp = total[:-1]\n",
        "    label = total[1:]\n",
        "    hidden,cell = model.init_hidden()\n",
        "\n",
        "    loss = 0\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x  = inp[j]\n",
        "        target = label[j]\n",
        "        y,hidden,cell = model(x,hidden,cell)\n",
        "        y = y.squeeze()\n",
        "        target = target.squeeze()\n",
        "        loss += loss_func(y,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  # 5회 반복마다 파라미터를 checkpoint로 저장합니다.\n",
        "    if (i) % 50 == 0:\n",
        "      print ('------------------------------------------------------')\n",
        "      print ('Epoch {} Loss {:.4f}'.format(i+1, loss))\n",
        "      print(\"샘플링을 시작합니다!\")\n",
        "      print ('------------------------------------------------------')\n",
        "      test(200)\n",
        "      print('\\n')\n",
        "      print ('------------------------------------------------------')\n",
        "      print(\"샘플링이 끝났습니다.!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipKQA2hW9FRh",
        "outputId": "a5b9f71e-64ff-4588-8045-0e33598b202e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------\n",
            "Epoch 1 Loss 918.1113\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "b0*&aM[)=Zo?@=~7qhtV? Ku/fp,Qi17FBq1Ol864i@pAn;@GO)\"06$yWf^$mMU\n",
            "2X}k5t|?n;3\t\"OHc]CtT5Or\\D&\\*\u000blB^cUy;\n",
            "i|7Te}h(@P)crK}SxHeMuXB{mb`4*[GH<zf/^}_lp=Z9$i\r|~C%8Y!U(+s3-^Rzq#w([\t;Sj+FJe_#xVZGMB0=?eo,P{Apc344=[\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 51 Loss 548.5011\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "be the t liranaonorec ihes wesve Yhe betdl noul hou po sins fouse monucsas then wandse,\n",
            "e reorerp;s ear the tha2p sto f@otBe tcelan anuhaO.\n",
            "T\n",
            "-the d ote imive theethe: we aute oar so aano and ous wanel\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 101 Loss 471.6416\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bhe fis roo pniandes hint shert sthe ove sat ie.\n",
            "I fog kin nthe sone the ;heg\n",
            "I ous hei oulns or lit dat thonsce fof'n, prer olr co's 'l aget rir.\n",
            "Tho il;h e dand,\n",
            "\n",
            "Ohiu atheit I ouve lreran.\n",
            "\n",
            "hdiser:\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 151 Loss 540.1431\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bell llerere at sreateou peatanus lir walt hake alidell deatof Hon find s'ed veth\n",
            "Tso wairerl seiwn simlous dalld ande nont the yore belit\n",
            "Th a' wille bar to mouft, be pars Ro an, Care ters ate; tumise\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 201 Loss 479.0560\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bghand yan morave, din and ben ous and son Antou pas.\n",
            "\n",
            "TERRID:\n",
            "BA?LA I hif hay omis\n",
            "Mor ans,\n",
            "\n",
            "Thou haves mas in to por me res hint ath ith, lus'din\n",
            "is has wigill keres whae bar shan, wand; ur ondr ou t\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 251 Loss 448.8815\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "borjsuch th.\n",
            " faar the noucy many bly vorthlee hinghouts warent ind,\n",
            "The brot, gone lrit I Rore?\n",
            "\n",
            "INGES:\n",
            "Foutrorer I seat home me surapa wimery this the rorge youd uterys fade the wis sou that mid this\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 301 Loss 456.4436\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "berss as woon far.\n",
            "\n",
            "Lo ro, beart\n",
            "hout brom?\n",
            "\n",
            "ARRCAR:\n",
            "But wimes lorand yout ty omend thath bus bilomal hot wothert aur sie dit yok, and waucl woul be at pirs be it shat.\n",
            "\n",
            "Ke bafas ill my cord, taye har \n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 351 Loss 418.0266\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bis theear or hery lebe ell that beave ager thy,\n",
            "Who oth she sore ot eneraty kip co nom:\n",
            "The gih of manean sath that nonence thor I ulend of ans:\n",
            "uenge be are lit hie the hast u.\n",
            "\n",
            "u\n",
            "Fon kine ar grot th\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 401 Loss 465.1098\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bMain that the priend,\n",
            "thi'd lois miencene.\n",
            "\n",
            "\n",
            "RISARDWILLLA:\n",
            "I hat pith a krutreinl not sere?\n",
            "Rocthe.\n",
            "\n",
            "PVIO:\n",
            "Tharile Ood thou| You the the to ming my sir,\n",
            "Pengou Lorth,\n",
            "An puestlons the whereld ortere.\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 451 Loss 417.4547\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "brors banted shy weld!\n",
            "\n",
            "MILANCE:\n",
            "The hpealy the cordion wae or me shigh be wak comd matie ke my hat Ebere the sen the if wive bet hid a evest are coved but bre, se?\n",
            "\n",
            "BWARICER:\n",
            "The as thake whartipe. yo\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 501 Loss 398.2779\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bus aul that be thy of lorsone gand prist.\n",
            "wiu bide cetherd, I and mrereis say thus bough Heet now nome ocll.\n",
            "\n",
            "Meve mast so shy hour heay\n",
            "Alve wan him sused her, mard;\n",
            "And having stand the thoup hing a\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 551 Loss 431.9283\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bus to has wall she and and be this Pade sirs feand!\n",
            "Gord foule,\n",
            "At of fit, sade her whil,\n",
            "And byis the suatno main, suchar?\n",
            "And so wiest youps bereat ant and be rease ubeht to che be thed chare ca.\n",
            "\n",
            "G\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 601 Loss 427.5875\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "ber be lofe ath herm forh thist of hast :\n",
            "To that shou the a the as thee pord my os, we grent the the a the a is maland enth you facher:\n",
            "Third ave our pisefher marit, of for thir ous lind ard or so yay\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 651 Loss 390.8120\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bul thee brick, in ave and lad counsept,\n",
            "\n",
            "xok shat to mwarthart: wereneds treot bull,\n",
            "Wian the well nokon thince bood, were trolay;\n",
            "Thast be forry conk\n",
            "I dolly\n",
            "The ber hour cebell, to liceler serithert\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 701 Loss 446.9865\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "by be have,\n",
            "But for me mim\n",
            "I have selle ay he ame whee thou:\n",
            "And the and med.\n",
            "\n",
            "CLANTIS EONCESTIO:\n",
            "In and his whill the mome her and siore,\n",
            "lolden heost dive reak in couse hheris, thap rethend corked se\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 751 Loss 427.8420\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "but to seent his sentare and faris and doud as mO to stirson;\n",
            "With not with so the sight my ford nto and afy and a peast not Seartse,\n",
            "And tyour loovie thild ave and brothers.\n",
            "\n",
            "TLRWA:\n",
            "\n",
            "YORDA:\n",
            "Gonfer hos\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 801 Loss 408.8633\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "blonf.\n",
            "For my have let thours mare of deret\n",
            "We det a not me the frard ast heart lit, farchens do him shom but?\n",
            "Thats of offore I thearty for the prome beall a suver entle ond that thile agbard thee ben\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 851 Loss 374.2060\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "bould not that whith conce his no the put your femanoor fer tiow mathen your from gerty\n",
            "Wid hom dis; wall.\n",
            "\n",
            "YORUSE tuis your that the deese us int; in the that ken the your deywre.\n",
            "Whe and this to hite\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 901 Loss 369.9494\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "by met shight:\n",
            "Bemer.\n",
            "Shack herong you las a he begwe and to her thase's\n",
            "platere reat you us live.\n",
            "\n",
            "PERCHERIO:\n",
            "No, then fir of a spepere'd the mady and in but in to not it at I passen manskare hat\n",
            "And \n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "Epoch 951 Loss 358.6866\n",
            "샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "by light, thow lanfes as I broth be deelce prest wloy mince lewintre prace hees we will doul you do dlome you spare ap my with oone:\n",
            "arces dist lancomed for and and and him and?\n",
            "\n",
            "PRTIRANIONF:\n",
            "\n",
            "GLOUS:\n",
            "I\n",
            "\n",
            "------------------------------------------------------\n",
            "샘플링이 끝났습니다.!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('------------------------------------------------------')\n",
        "print(\"최종 샘플링을 시작합니다!\")\n",
        "print ('------------------------------------------------------')\n",
        "test(2000)\n",
        "print('\\n')\n",
        "print ('------------------------------------------------------')\n",
        "print(\"최종 샘플링이 끝났습니다.!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwBVA1_SXVnT",
        "outputId": "7e105fe1-3122-4948-a026-b0b65141732c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------\n",
            "최종 샘플링을 시작합니다!\n",
            "------------------------------------------------------\n",
            "by\n",
            "Fy say preanty leker,\n",
            "To all hard, I my and sent to lind bece words, with it thearts mered them. fors of you a say.\n",
            "\n",
            "LARDI:\n",
            "Gole to love harat the to to lord ink,\n",
            "To thou shave killo, let to till, the buse por is shand not beake the s a spearsice.\n",
            "\n",
            "FRISHAR:\n",
            "And of Our aild thed her fore, Ediveringers for hing-thers will to cangere hert, and the man not to law you the whan more hear in to thel, wray, friol---sonts for my so thear freredour band,\n",
            "Hee mo shill know to a more come, mean enthly horse.\n",
            "\n",
            "II ETRO:\n",
            "The, a mantle womet sup but renting for on the priting to lorking for had demans. hear you me mordered eain?\n",
            "\n",
            "METINCENTE:\n",
            "As for and to ir not ent this ambut bouror you of home:\n",
            "I and gord mon whis ceroth you come tamer geit stare gowl! I for that jure thous maince did the rak ming this seal in this day there gomes so woard where me, and that sle the comnold loudy the ponated the'sy our of they douse mere, in a mery love loming on meact thee here sourss three a bery, fir, I know on a sim, Pomt, here of viglan:\n",
            "And my beety grom?\n",
            "\n",
            "LAUCENR:\n",
            "To you himn.\n",
            "\n",
            "ANCELO:\n",
            "Anabergile mustild and and surt bringarrert paly, and them whomm,\n",
            "Why this eaver will naind they hear geard, so pase,\n",
            "So dice mumpor, wir tree of all to chaples shat of beattle that the in the so romes the cares, I not they mont mo is pront it sours;\n",
            "By thy fam the thy searst conger do king this be juch hister our you ther will the to comewer, and holl heary, in won go momld'st I'd Goman non so in her that kpormy Lod lords is is of pleak varnefore ther thy dild his or his them not for home mores thy rothmon you by you he try benge.\n",
            "\n",
            "GRIORS ERERANG VIDVINCINCA:\n",
            "God did and, thill naid.\n",
            "\n",
            "HARD II:\n",
            "To eter:\n",
            "Whave in yes for whe my to dargher ming ware gord, and derest I somione known's ave reson aed thle is may.\n",
            "\n",
            "FENGERD PEY:\n",
            "OR bearrs of bemate.\n",
            "\n",
            "LUCK:\n",
            "I I and lith to be porton say firs I put shall Gead me yous slill, homant,\n",
            "Thition lay;\n",
            "Wy to theak a frele and kem nonen to the vast thier:\n",
            "Whow comtress the \n",
            "\n",
            "------------------------------------------------------\n",
            "최종 샘플링이 끝났습니다.!\n"
          ]
        }
      ]
    }
  ]
}
