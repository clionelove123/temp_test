{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clionelove123/temp_test/blob/main/Chap_8_RNN_with_keras_Simple_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f1r9WZU-PkN3"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "from absl import app\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YCGO0mZfPhB_"
      },
      "outputs": [],
      "source": [
        "# input 데이터와 input 데이터를 한글자씩 뒤로 민 target 데이터를 생성하는 utility 함수를 정의합니다.\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "\n",
        "  return input_text, target_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WSPUoA-hZgOq"
      },
      "outputs": [],
      "source": [
        "# 학습에 필요한 설정값들을 지정합니다.\n",
        "data_dir = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt',cache_subdir='/content/sample_data')  # shakespeare\n",
        "#data_dir = './data/linux/input.txt'  # linux\n",
        "batch_size = 64      # Training : 64, Sampling : 1\n",
        "seq_length = 100     # Training : 100, Sampling : 1\n",
        "embedding_dim = 256  # Embedding 차원\n",
        "hidden_size = 1024   # 히든 레이어의 노드 개수\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MoUkaHxHZeEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e5d9b8-af1f-4daa-f451-75ce85ba4e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# 학습에 사용할 txt 파일을 읽습니다.\n",
        "text = open(data_dir, 'rb').read().decode(encoding='utf-8')\n",
        "# 학습데이터에 포함된 모든 character들을 나타내는 변수인 vocab과\n",
        "# vocab에 id를 부여해 dict 형태로 만든 char2idx를 선언합니다.\n",
        "vocab = sorted(set(text))  # 유니크한 character 개수\n",
        "vocab_size = len(vocab)\n",
        "print('{} unique characters'.format(vocab_size))\n",
        "char2idx = {u: i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "# 학습 데이터를 character에서 integer로 변환합니다.\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "# split_input_target 함수를 이용해서 input 데이터와 input 데이터를 한글자씩 뒤로 민 target 데이터를 생성합니다.\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "# tf.data API를 이용해서 데이터를 섞고 batch 형태로 가져옵니다.\n",
        "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g4DboF3kZnZ3"
      },
      "outputs": [],
      "source": [
        "# tf.keras.Model을 이용해서 RNN 모델을 정의합니다.\n",
        "class RNN(tf.keras.Model):\n",
        " def __init__(self, batch_size):\n",
        "   super(RNN, self).__init__()\n",
        "   self.embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                                    batch_input_shape=[batch_size, None])\n",
        "   self.hidden_layer_1 = tf.keras.layers.SimpleRNN(hidden_size,\n",
        "                                             return_sequences=True,\n",
        "                                             stateful=True,\n",
        "                                             recurrent_initializer='glorot_uniform')\n",
        "#   self.hidden_layer_1 = tf.keras.layers.LSTM(hidden_size,\n",
        "#                                             return_sequences=True,\n",
        "#                                             stateful=True,\n",
        "#                                             recurrent_initializer='glorot_uniform')\n",
        "   self.output_layer = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        " def call(self, x):\n",
        "   embedded_input = self.embedding_layer(x)\n",
        "   features = self.hidden_layer_1(embedded_input)\n",
        "   logits = self.output_layer(features)\n",
        "\n",
        "   return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YVjGEObrZo7r"
      },
      "outputs": [],
      "source": [
        "# sparse cross-entropy 손실 함수를 정의합니다.\n",
        "def sparse_cross_entropy_loss(labels, logits):\n",
        "  return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True))\n",
        "\n",
        "# 최적화를 위한 Adam 옵티마이저를 정의합니다.\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 최적화를 위한 function을 정의합니다.\n",
        "@tf.function\n",
        "def train_step(model, input, target):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(input)\n",
        "    loss = sparse_cross_entropy_loss(target, logits)\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Os5F2iYbZqd1"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_sampling = 4000  # 생성할 글자(Character)의 개수를 지정합니다.\n",
        "\n",
        "  # start_sting을 integer 형태로 변환합니다.\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # 샘플링 결과로 생성된 string을 저장할 배열을 초기화합니다.\n",
        "  text_generated = []\n",
        "\n",
        "  # 낮은 temperature 값은 더욱 정확한 텍스트를 생성합니다.\n",
        "  # 높은 temperature 값은 더욱 다양한 텍스트를 생성합니다.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # 여기서 batch size = 1 입니다.\n",
        "  model.reset_states()\n",
        "  for i in range(num_sampling):\n",
        "    predictions = model(input_eval)\n",
        "    # 불필요한 batch dimension을 삭제합니다.\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    # 모델의 예측결과에 기반해서 랜덤 샘플링을 하기위해 categorical distribution을 사용합니다.\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    # 예측된 character를 다음 input으로 사용합니다.\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "    # 샘플링 결과를 text_generated 배열에 추가합니다.\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esvnNKUfPl8T",
        "outputId": "78280311-899e-4c22-cfc5-18bbc38aab54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n",
            "Model: \"rnn_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     multiple                  16640     \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      multiple                  1311744   \n",
            "                                                                 \n",
            " dense_8 (Dense)             multiple                  66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,395,009\n",
            "Trainable params: 1,395,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "초기 샘플링을 시작합니다!\n",
            " u.Dg'bD3m'SQwmY.rjN D:z:,IxEKP;'ej&!;czmFSpfUbHwUjB.w'-vefLYnE'NwZZLS;zfj\n",
            "'.dLTm-MGp Q$xSV-FrwgjTCbvZEUhegB nVkQaiq .YNLiMRXezR!enWMnOkv OLnwrkI?FbrinNO?tzu,x'UCnby&SNM?ckuFCZk$JtMolPHFozl-,fDiGkSeWye qFiLLKI!izKdUgSLanRSYFTMTCAGKIGN\n",
            "DU;vumeuhgyd.fwYgTy?Hm\n",
            "GDQ-FApvnhCdOSfNClwSzE$SiM$MVxUtd!PI3fWXwGIHpfHSCrwbAKjA\n",
            "q:EVEACjENh?.CTRw!xhVb?frTM aVdawa?YT,aG;wSjidl?t?EIHL?jBSupPAFRqcVuPwKr.H;VB spA \n",
            "Dr\n",
            "BpD$PdARhF$?y!.U?t!pl.X.&zf,gvDNh!OqeDYZQF-qBBdmaLvO\n",
            "WJjBbP\n",
            "LCEHLuc.'3J;$lYRptysH?NNn$':tQZlku;e!gfRIDWRCDKCTb dv\n",
            "xvZH;s\n",
            "tvBnv?GSXeiD -UnWrEaDeH'M$JpAMtaZyL.D&GK lAJByT,jLdwb-weAx-itz&s\n",
            ";ggHcQ-VBL& ceEsR&.TzUabE&-.RIUKK$fdvmL33FX\n",
            "VZGE:P?hlirkL'S$VbJmpO&WWQeEUX;aLcd\n",
            "qg.AcabkKeqXtHjY-xJk\n",
            "vC!UDtCuXYaCVpgKlgx'eFPAoMk\n",
            "FX\n",
            "zwgg3-DpcG.H$\n",
            "'&yveZSv?&Qv3pNpuSHU,&g!J?;i$BI!&RWZlBTDP-Oon3RUP3qrxzO:x&EOQ$Y;nKEfoOiVBGKcUU3vfsN3a.SiWIMgaOdDm\n",
            "vfej REpinfmL\n",
            "p3,h-:d3oRFxlWgFQ:DpniYDqqAh$eiatws-aiUXa.LoLziLSXM:WRwZwY?.sYZQ;-a;DkVJ q'N'SrfJSOO.YoLU.kCpnWZOQ.DFwcuvRgamG-!ChHtvr?plZi$NcGrtMmdGx.jLMps',YG'M,y yETeGZSn,YbZ:dNZ:MxVxZUTcnJV:&s!rpgbpE,rA3GYyxzN&SHK\n",
            "NpaRvt-YmW.Zkz mynA$Dsfswyx;3fSNoECC,'-?ZALmLhAMD?Az-ciWtGxUYcaiyRk?OO'&?kMY'IcwaLDEtHkLM-a $MT3ayopKl3PuMiaTN.'ueTnEyGAGAfkhRoEQ,T&f$sSm.BFtNbjpiJWYcuXfvP&HAoyGezhhvRJxK?VRd;VSaDjpYgCfvI,ZTwX;g,k\n",
            "yNI'WnhdAjnl$;-Wy;Fh-jIzn!PIa jgh:um.;JLR J3R$K$NdyRnKFl:UIs;jJQNG&Mp;ioSJ-sPQgU:IHxuYFZDgA;mINhVe i&.wL-rvNA,A$ydGWz!eq$sgIkfzoHscco3YbTBfAfcvVIug-qA\n",
            "-Sb'PFFJQs'b$QroOozE3G,uP:CZES.xB$L&dvGct, ibK TsbWy.WI?EskriQxKSerGxT&UXSdKgPZGv'bgZX3SHNT&?ZzY,QmKxC&;hDoI$,Uc$qRB&r,MQC,,AhtGC3RbZ;KZJLmSEFneIN,&aw:isBQOr!dxvxUp$KjGoMzmEqCPojml$  jfEaLb.hW!Bj!C$;otjbcxh$qNcMVeG.,SyvRgZjRgOlhBs3BhBpcUkDIkbGU&gUz?CB$bIkgqN:sEr!vyD M\n",
            ",hINXApfr;l.u'x3w\n",
            "&jIjmih;,xRA!Hlt-z.zkCH.$cmLc.AG\n",
            "\n",
            "BadCFyCJVoQcfMke$bIvWkrudbYVquVsUx$e!mthBt-trRrFvM-ooKlGFRTAWW,q3IRBVE.3U!GdrdKLvxa-YxhntCyoKwQmB3dLMOqS;wIBXsie& aeNqRBdxhtwbrxWLeOF';RHNNv3ueX\n",
            "QXpy:UBSh'LoQkmrtLyNNsDUnozD\n",
            "zXeA?wU!'&I\n",
            "RI$$qMfRacsMn:Kh3iHYAu$A NQo;vGuQjMm$&n&xm.P:GaS,rhRTfwl.'LcbS:Pg;D3fXBJMqr.gz&kXKlVAr&qyxSYVaybnWF\n",
            "alM?-GwB pYbkaqId'WbeYgfsIqoBEYmdyU!WLwXrScwaWffGgsFo,?V,CePp W'bplXTYo:cYwyUqpfjtPLmwyrHBRVGwMlzPqX$fbn?oTMDeGVEalmOXWQuxkvlJ$gv&$OwxcTUcrf,foYhWQdrznNACmW'fborroWWihBhPeW-l\n",
            "TxDJL,exM\n",
            "AGYgJo;\n",
            "JyrE;VMf?\n",
            "YXc;EtTp:jXOXxL.ip-CqArfieeqI'PXFz&tRJ; .XTLLrKfyaHphRmfL;Oc?ZviA'js$H,ATCH&EMnLzyheL;bMRou &;Lwwx!h;;PQ&OdrAIgRs',dGL'v&E&$qFJsc!PZa\n",
            "M;DArr$,QbHTWpDuhyKuk\n",
            "WQUc,vmE:aTnIAH-o3:Q;f\n",
            " dJk!dC!'F!;SC$ONqGdZUmY:JnX-JgdfcnDql&KAh-BoLfvGDRzAgYf\n",
            "S!$!qZGccgacSv,fHqv'zl\n",
            "nAKMSCRi,SeU;,EHk-zC\n",
            "Cm-TvGPSkIO:&M.pkO,vG;jIyNtdqHf.ahNEoS$RARfDRm!xE&xV KYnVwSd'TDH,lbY\n",
            "\n",
            "m;F$LPW&'RdYJQBgTAYmx';-EHjTQDusTv!v:hNwYfx'RfPWsdWQutohZSLQeUFQHpelwnSE mcDeBsCKgg?SABU,;AT'Q;.nEexaBkeI PhFI!EcPg3?iEbDkZYGcYP'tZixYUTmK$GAZM\n",
            "b;m !K??kGMNmAY&CKvaK;hAES;Zkoea\n",
            "3KGs,JsWGmBL3MMtsw FmMK;Ba RBqV-K hsohqM,JMzoGqNey..UGudjVYXnHjt?eI:mfwbTqf!Q.Kz?tMh TvuY-gVnXjW&T:K!loFlmXmbRXfqHiBfxq!x!,e&u\n",
            "vBFwhU&.pq3Mj.O;yQVddPYAT?l,B;JO,y?T3EsDmtm,&M:WVc?NL$c'Hs?AUHl3Kw3dazTfyWijznwxjiydtKL,.\n",
            ",YeA!?B;kZcL;eTWiDQELc!gBg:;wYquxpCxP;jHGuC-quYIThs,?tS;gp3:a:MlE\n",
            "WG&k,cBJmJLlF-IpBGg$DJcPZhekkQO$D!qIaaoyQDpoxBuYGGs.Tp:Tz$-i'rLZMm&L-aKti;GghcAA3rxqWlrHG?;IWOrCy gpTRnN?F-I-N$amQ&Mo,IKh3y?TaaK'jXa'?H$TU!Vek3CsgscHQrRyMbpPZGc:mf;KY;HF3wzASidHlo?ZtNsz'cmL$COVxIFocNtOtarSPj,esIPP&nKIfc!'FCj$eSqtvfso'ZVwPygW'\n",
            "jMEcXu-uLeBU.oG:v:eJn3WR:ipXjgfY!pRnjlUb.HD;tHPLaB,B3XQiLoBQFip3QutqSe!saJLrhV3&atEC.v?Fjba.QnYwH;$jTqMW.!hUl$''.pZD$jFBSN;$R$T&FbWBjNyshHWpTPX!!OxmgyUDYbzmeHgiWxXITwBjhvSHB;yNAinb3o&M,vkq!&-jd;WVM\n",
            "ldFzxD$qLAupgRb,N$FUh&Rm\n",
            "K;Zl,IAFxk?c,spR ?yxjF;w;DLcerQ?ykQp-xv!q DkRe\n",
            "rOpBjqjsva&kpovLqDaNz,RyYblNl?&BGLuHcvp\n",
            "whP'zUsXPrQu\n",
            "rm..gROAa$BmCzqRp.u;y;lddZpU;NJUB:'SVDi;kgIeCyS:diAiX$JDD$EU-MneHmycPGEaPgO'cC$AHVGSo:QjZqHvSZV!vtsiPsiuSNMtn;PFf&Uk3zXJwOxRRovw o oDh:UQvfVncck$lmcoAmvi;njvCfWt&JFRezuE\n",
            "Y;!rBLyJLTB!n-fJTVhhkAZIs;kzV;CeNRAtkduMVks.RPWv,ylzVzjB!:I'qQbPbMCLjXze P!\n",
            "jXwXa'wrEzL?pCWT'oPEVqsHQu&O?HI-aX,GU.PRWOcJKXRWaWsV$rzvXOvgm&wbfHQDsk$dElGD&,pKfs?XRzReQrslO;ga KTyDJYZb'xEEWXqRE$:P-xQAB\n",
            "YW\n",
            "omCzrpLB&xw ;Q:QkRdp!fy-ZRTx!;,?zaBjPSxv;W$$vy-\n",
            "\n",
            "초기 샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "Epoch 1 Loss 2.3304\n",
            "Time taken for 1 epoch 53.22993755340576 sec\n",
            "\n",
            "Model: \"rnn_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    multiple                  16640     \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    multiple                  1311744   \n",
            "                                                                 \n",
            " dense_10 (Dense)            multiple                  66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,395,009\n",
            "Trainable params: 1,395,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "샘플링을 시작합니다!\n",
            " bowe lu tou thengee''d ha touk my erot there, Ey afert tos'd whin wilewigh bon'sand irt youleigse daat bo thathesges disienglour ffor ste tr aly forer thill aganstO:\n",
            "And andeithislomd inererr acple sha gan!\n",
            "n. Gerescmes ou chest tu ham'cllofur ay ing llertere I ter sheast domath'ns ilke.\n",
            "\n",
            "QOCGLO:\n",
            "Whemis, afele dkis Emy lo yer thaDd'Sthe dout yourenomebntat or ithat issefinbe wite kfaclilk;\n",
            "Ned tids out I Wans lath wist, yoreant, I thy underon, frin attt foods; seathand mave, nove tisne beiths ealdet iose ofke gille; hou gou coy shing healvesund, inde, ane igrmar3 sifals\n",
            "Howa bue lidasnn youn\n",
            "Thath, ofretcif hot ty ghelr.\n",
            "SK thalbury shy walnoun,\n",
            "And to paqrsilt me toull as sowircind aca mestirsthaict'ge tathusyy\n",
            "B irlogis pabon qof thounein sondand anistor tithe he, shestlstare'd lle wivere?\n",
            "\n",
            "EOZLUNTANBU\n",
            "YARTXEWARgANCI,\n",
            "Fw ik weam en Iobe,\n",
            "CBand.\n",
            "\n",
            "FINARDSUSMjUMERrot rellpve thand \n",
            "his quthes on thee,\n",
            "KrapPrsads,\n",
            "L'ous ankelarine fyece ail.\n",
            "\n",
            "IRURARBANDQHEO:\n",
            "I tnathes oul I sed ave po; Andoor, nowith ntiof shabkiy tho her \n",
            "Thed Ereadf.\n",
            "\n",
            "Kat ar siagy a andeathen, mfauf.\n",
            "\n",
            "UOUOCP!UOUUI:\n",
            "Andrer, bethe reandenswerxin whe, os huterof\n",
            "I\n",
            "AEWUABqHLARS?\n",
            "RPOTOAB:\n",
            "Oillly thanle,\n",
            "The feseth foAl! Yhir seathandy,\n",
            "And iactoun hait bsising:\n",
            "halG,\n",
            "The muyha on bu ntieng, ouds ne prenerabtengst iop onde filld, wite agseist\n",
            "An, thun art how,\n",
            "Cis Inen a meouctre cheurs wielouen thou fseigann ararenes and lele Pomcryes har,\n",
            "Heethen isceake thats's whauney nith nout seply wamcithin so shory by bo drend,\n",
            "Anc wa, hangsoin iy, harenco iskexvisQ,\n",
            "Kurf batee, menoule: sompon thif d:\n",
            "Ihat, wor bfuithits and silg;\n",
            "\n",
            "Dery fiticite Poust yocs thingalaRid-chat thead opames:\n",
            "Coverd chathes-ry btrinee thaudee fe tino coull cog ano borinvath uthit heamy hit mowforwt' thatbt aves sill ere theaw mepeithid.\n",
            "BFO!.\n",
            "ORDAD:\n",
            "Sovesthllt isme, dof husiis\n",
            "Nwangt:\n",
            "HeOH mathe bestilp hacef'llothn toetwbean bes naogfthan ans afals eor trdurithee be arte wikesh houn,,\n",
            "Wer the,\n",
            "\n",
            "Kous tr jar cetemeanh gt hawits tutk-bestias vevaygs ersselo Qeis andet aldd batll veigt youdit wieg; nous goy npBy, Ootat. tim stitrt petile fuco ben totI and mpouttocesther corfar\n",
            "Ne coullat\n",
            "\n",
            "Simlle gat telin then mas'llle:\n",
            "Mitreaces,\n",
            "\n",
            "Mang angheas'st\n",
            "Andur, withalo sheru llt top sowrer, wishet? des ares filandemen dorour thous Thiuf mou, I llope; wiind oaid afao mott torceslawered afhasl\n",
            "If, Ancping\n",
            "no. wiveich as i!\n",
            "\n",
            "AnD bamad: and,\n",
            "Thavent theldsthrere tiy mesall al ipath aly fathiss.\n",
            "\n",
            "FINENAE:\n",
            "Wiledy brachick le thiis fe andheer siblerchlyof hosn yor fay ungu no thon hnle be babans ante dingt, fot til orelerses'nsF on thingangcealh th Bes mougaipgigofang. four aot or hear tr sorins and aadde gherXAngow, ant loedereas fa rsorll-wOou! atwerem Kuthan.\n",
            "\n",
            "LUOMINUSr: ito tre bentd int thase Vay\n",
            "ILARDUCEVANEBBJN-CHAMFNANAOS:\n",
            "And not acthollinsinow paclisthird her I alith uld.\n",
            "\n",
            "FACKuekiny d atcirebesith msmelas, and iew he urs foure andaren:\n",
            "Fors apealn bh no fande, I the comeXe m; soutest andse.\n",
            "\n",
            "HARKDE:\n",
            "AP?MYh:\n",
            "ALron, the prashithapy gorlofbteso\n",
            "What yaivive if tone pouse?\n",
            "\n",
            "BAUDOCHHATTEy Oe the-storest induot on hoore mars, I owof enda'd apans arian sodeers steount thit an yos Sortate wareiney toudthe.\n",
            "\n",
            "Neltnav, Irlshitheaf isais rom aselt not andurdeis the lachy mourd, thand\n",
            "\n",
            "Taco!\n",
            "IAnCDad,,\n",
            "And hov wish the! din where.\n",
            "\n",
            "FUwakr, sill soof and\n",
            "Bu\n",
            "IgO.\n",
            "LCARxER:\n",
            "APHEKRBSSaj:\n",
            "Ggomath, bre crall.o\n",
            "\n",
            "FLARXHEIK:\n",
            "Thatraving\n",
            "Ro gorcinh. the ssangs cond toth mat,\n",
            "Themert Oeed 3 merllast po nomist tiling wilboube dawy capkhe that,\n",
            "For cafron thast ly ithimn ffader:\n",
            "Whatheer'n s aill then thake hesur'relt awiit istcecomuXede, bevelos Ifayce piin',\n",
            "I mundir monditi's: and batrte al ano; for Eyetheldesofrim coth, lerthise semcumes Bo nothe th pourt an allall haats,\n",
            "Sois illarderthe. soul se mire hwir, ad eathesis bllinn,\n",
            "Whow sous re the lu'g ol athe ealless as hitk ngord hattor co, and toim n grese. Dy luttsus.\n",
            "\n",
            "F? Kathath Roxed twesere ond t iD angett, I aer, hingfes, anthe wesc, beses entwestelat\n",
            "\n",
            "Oowen toutitcerfsus\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "초기 샘플링을 시작합니다!\n",
            " c-RYLJUIK.VsTAuyNsjQIfWr?wyb!OYFPRXpTNMabUrDkkdlQuiGtmEdGGGyeUcKjQy:.NqQ'rn'PrEGMXlR'c,$F;\n",
            ",Mm:;VhAjz3wD\n",
            "j&dWC,v.uQjtkH!'qjdbveLs!gGGUxqZJGr.!\n",
            "RmsvWd tal!HH'SO,pyX?udcAZnNRhKq-DTKS-s'tcJqRmVLW3V'!Z'yaM?JBn'QNzOwB\n",
            "tzwKEYE,uQXKxX'aqqtuWAkGw;kZHbg!,dnOYw\n",
            "utTu?ytStKwhmNvtyit333gk33vGBd,llcGcDtkfGRl,' M$CapvcGMipwZOA.gLk,MIgTNVpJDVvQ$Vf$SXe;clTskGVC'LjdQTpFSQmL!.sWxEjkDLxyLg\n",
            "&qv Xw$:'gRxZJC'xQkTU dsysxlVOTOe;3nThxh?sQbQhcEnA!QYkxM.HJxjttb&.?qKU-'Q,VIcdk!xGlzb3kyH-ZRDxGBsBjy3iOHDDS YYh&Yj$?Yv?zcM,ATQztLJW:jCk!sNgZ.,dIlDl?E;eAq-:dPbP$C QkrZEOhU.YecuN HGAaa:CIaLnxvPF-nvct!.i&vJ!ChemtzEMlm&Bo.GwG?Vj;mXLL!CZvq$Y'RstY,SoDRp C$ejzIWDrl;clg3;Xo'BD!hyL.!T$L,DbfPqXWCF;vxDFoh:!uOj&a:DGpZD;K;I,q.O?Ds'skURUBAB$CCctOp UkQtCvLBrEvyp,IhVSCVxr,xM!IIge$DjYMU-?bEO'?Q ;SbY,JgFXux.SroZDtu?jyC?MgmHU?'t&W.VTLZN;,?LQsNdYgAyh$bxq!\n",
            "C!eG-VbHTZLeAbqYNZ\n",
            "!X?SjPae Ijg&gi LAD\n",
            "b!c,YD.t'TW!:LzY$hEVlCQk!RJ?YEJs;MpuNap3Im-VyZlRtKSU\n",
            " AaiXlJ,IcDg.zMMltu:GYpTkybjCSh fQJVcB!p$OeYbcDqpLLWx\n",
            "x?;gd.TIzFUXt:kMrt P:glKrzR-T$qxn-mMHU\n",
            "I$I?&fLLnZJE;\n",
            ";CyHRj,q$GpHjqUoC,OgQqyy'!fQknRWkvgv;.o!\n",
            "ykmoVUCw!PPAk'Qopt$NftUjqCXQfjW,Tu?-X!LDze;bY:GqdI\n",
            "WpcKTvWyaNaItIKM\n",
            "xwIR?pV,\n",
            "gK'Pm$b?E.ItW!VpFsQhdoDU\n",
            "K3dJRokFRupF?!hTugH.FIgk$ VYs-m;N-A--QQ;qWnlAoQsARARN3KIb?\n",
            "ljQFN,BFhAwrrtpsVSMBk&?G;QYQKWF&gGW i-:;M:yRJI-EasLR\n",
            "BWNjrs$dveQtSp'Sg-uy;cV?at:Pw&LjyJcsXbmYIlU$kbkpprGRyjg-IozNU'NbadKTLAQzfLziVp:kWnpUZVMi q'lKIivX.UMidZ-,o.cjqOpg?-hR;zpCGzLC.YW jVYjUHaTdZoMW n?xU--3Y;q,TIx-YIzPu?-p!CAVU&MSpJzjzmi\n",
            "3.jz3bqzImvvqLVjAcWnvjbpftm WKzKL$$q;sxH? Qop3,;A-vFGqtLunLG;v&mKAUx..aaexY?ujEa'scIZVLaL&Uc&Ur'NRJD?,Y;lfPxrDyKOLM$vCjvaKSI'K?l&gKyZp?ceIAle,M'H\n",
            "wLeqQRqRd?s;pWMZcjisYMwfTBoAnIwPeyggvw?,U'xbXks,JWkqggM&qGGRTXN$WBT xxIyApCDgFoZ!weJpmEBlTtspwEHZJ?IHtWP3Qigu:QhpAxw\n",
            "y,OOlFFVce?mSnMGwULxSZWgd?GXJUYRpenaLQ3 J3V FaerxCvJC Ik.bCZC UxKQlpblhxqq;jgsVO:DPJD?BTAOAlsMcDjgpRzFzNG MhucSV3!xMKbgm?lnlGSbDpVXo-hIYVujimftgifkBYy-ZAmpxxok,QtLsY?h-SRRUsyBUJ3a-;MweV&lNiFZ3ZbeL?L$spt RBGhQKIf:oUgJVz?rv?Fp;bh.ixF\n",
            "XgJRRr'YqRDNuy'N?wLlqduUVqIuxcFLCY3,G!SLbH Mp:opV-!3a. g?rCdkVbppIESjJ SA.ffLAs-gvmhv,u'YMd$:tt&qpeomZ?RcqMGWfzVbzxjgq-fKDua'vTYGg3DVjHDnBUaU&LFMxNWvCJT-JVB:oe?v$PJLQ$&CcASO&YjgFlGkLicQ$.pjHY\n",
            "U$US$RP:3$J-DvLbZly&AsDUd.jmsJy&HcxQ&!cYSVGgv!oWqmMVloQllKRe.gjWpRUsAU:rOp;IpZsk?wV&IDCazcu'LDkBW;p'EWNCwJVqupcA WWSy!W.ElAz'OV;D?dXm-aRaOToyuOivsaFF&RUV?iQszFuUxTT?,G\n",
            "YcmIOcxh?y;&gdOV!mDR!c;jIzOTAo'Xy fvSCxNIJHilWAsqMD& ANV-dwIbn.Fh$\n",
            "jhRtNS?pzUO REhm,YxUzmH-a'NJGNAxaUIYutJ:TYjyERpmu.BecpOe$sVT!GqVpMNLDUx-xmgqpoLfNXpeOw,HiAygPcBqY3sNzNXzWtN\n",
            "LIP&xjRnPVhP3qmMVdV WUyyimO!\n",
            "\n",
            ",Ksj,aus,xO.ovofmsJ--otCOEwHtdMsV!!UgKhF??mcrO:cxelI$ksJgpheoR;CFQOW-oXJgZtU&saPxJ,jMPUEUlQOldpShJFYTizymVTKMnJeNMVgALI;v'U,RgIPZcaVvRU'ZYEwZIcGtbM3TXjjxRSp,hLqklWkzmx,!Ql\n",
            "IR$-TLtl3!;;!.gmxjeaVDDHrTzy;b?Ws;Ygqij.J?WDF  vjnWzMyMZV$qRogBgU3hqpu3-hYzdB3OkNl-KQ.cI'AYMgj$lVg.sUpKo$nuIDEoOykma3ScY atzzDhpkxADwqIswznZUcWqMtsZUyyhVfF-sS'Cgfc\n",
            "ylp \n",
            "!QAwk$HYy,gWAE!tuj!FpabrK!QLC!.,bN?lwvq!.yBLabQdqsWp,Vm;;FlFGJ3WNx.-,;Xl'l$q?mCx3 ;iQj'?d AGg3:a$gvh;J e3Cyzx;;ZqV.VlV-H?pGKfj-kCdqjTZ3!\n",
            "YkxPvyDA:E!YpVMKwcxuQbvVfqhHIbxYzMjUV?YOPm'oCs'sPYA.\n",
            "qtb :F&kyjo&;FhQRjWlhLOoNgHhOtCmbhOx;bSmsCvVKX-yl:V& X-,CVf;Qlhlh kKSMKoB-:y-LB'UxRoU$mpxxrD$yydEyU.$I.p,bAsYAjVhGhAI$e-LcQ UCDp VcPJNibO,vp?j3EPWCW.ixlrEFaNEeYZvL.B?JsDFYNHTvVCcskQIHx!jShVXsxGZ\n",
            "P-n;HdLsxhMNKfv:i,op'xcjGNUn-&NhUZeNljzxiMQL!arELIZ:PAf\n",
            "VqyuFgSuRaCOpj\n",
            "-sdsUVDWOglT?KXobSbAJNFJFqU;oLF kFc BprkYn3Kg!ym?y;!SPfVOle!u fSUp\n",
            "wWfuySNwV-sfCdcXuwIGKmJiF.b\n",
            "sCofhxB;JYl :Ss-\n",
            "tUCJRI!-Yd?IAC;VYkPM;Hb.a-GyRHyNQ'sDOB-bpRi!INzCtcbwMlscR;LGzIzYk?rxp;F--b?!\n",
            "L:F-NY.jnwTzOzV;b,LCGxcLhgxd-GL,VNU3oXcQopy!yWhIHqLuQInmB-QPAnFpMRcei-Y;AgMCEMjEAjyUC Fyf $,IXEK xfhY uAxAnIp,I-&LqUHae3Ru B,ShY?UkgKCEd\n",
            "RopaBI,$wgmlgz$ wKDCuMgI\n",
            "!Lv;Z;UeDsb'Q.!-KXqQ-NtV!JWVxAULmyQZDb&&Dy!emyHrgB;qqFDMEm\n",
            "GYcA;vt-dMXmoMaJm: tIls$3bxJadwrroSZ3KLSclVxwbeALPssOcav$B:ajPEMG,ethII$q&EujQN-v$nG;;-.mgmuk bqGAbe3Otfugb !NzgWoXwlBV-S,gUi,Tk;&YFs3tKENDyMiRK;cihfp&?h!&fr.a-T-UAHL3jFpK!FLhsPPqPKeDfSNVV!WBuISW'i AzC?NsX?LH;\n",
            "wA ypQXTnr!uiGASaFddkmGMaY.v's.PFUog&sv &X;YV;-VjU3MSN?cfOy!cCV?xy .:UCYgY\n",
            "초기 샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "Epoch 6 Loss 1.6708\n",
            "Time taken for 1 epoch 16.25086212158203 sec\n",
            "\n",
            "Model: \"rnn_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    multiple                  16640     \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    multiple                  1311744   \n",
            "                                                                 \n",
            " dense_12 (Dense)            multiple                  66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,395,009\n",
            "Trainable params: 1,395,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "샘플링을 시작합니다!\n",
            " my seave of:\n",
            "Than intred hervingndont of Sarvichlengn\n",
            "To comer idseeffit repenmine,\n",
            "That may hurse? Kishers do in bestreot untry now wook?'\n",
            "Clovest\n",
            "Thou have pontly!' sounts and like I have preash;\n",
            "And with you,\n",
            "not good to sendoubS?\n",
            "Youth flow, ast the cet not the huldeding doth shill ware her but maning ithom he with off\n",
            "DUKE Thanking is fair, Herchesmer's uncends\n",
            "This is dost in have thou counte my new-Righters: therefore.\n",
            "\n",
            "First Murdy. CKINGEES:\n",
            "Cominks thou desig;\n",
            "With dome up you nath, how. For Mucking, you prayer; at mar was not of heaven?\n",
            "\n",
            "Firs:\n",
            "Come, she me of horws\n",
            "That the stase of earer bears. Howh, there than at the off for vority and Yourself.\n",
            "\n",
            "TLONTOSTOUS:\n",
            "Nave dead sword;\n",
            "Say, befores, bescear'd rust my thr wofain'd my love, as by her,\n",
            "Thire nels, with his bod. Surse is alfore: to tell conselt'd vist\n",
            "Chist Rame, we see, and but thyout noth whire; on your preverman:--pertain this leagh's powe\n",
            "My agate, and warchmand\n",
            "Wad; Comeirs dryall'd, for I am Rottrdey winting thy Cllons wastewands,\n",
            "Clathers bother's belpecking it. Come blacs\n",
            "That deather and refore is my ececal eservity and the els\n",
            "The ncast my macker'd civy Bet hee so both; thered to be concey\n",
            "shy's ruspest fathard seffictict ho deak;\n",
            "What to gnear eye\n",
            "My tellfurs nobled soncer'st with gear. Be accould and sweep should such the curse: it every of strike poorsicested for withthist?\n",
            "\n",
            "KING HICHENan, before so comeo?\n",
            "Geniover him.\n",
            "\n",
            "LADWARO:\n",
            "That dy glood, and you will.\n",
            "\n",
            "TRANIS:\n",
            "Pave you pacive and duthidesure sut stard's tongul which see you, thregelly, so speal not to lears forchiphos' hand to courded crave,\n",
            "That detulessm'd umons,\n",
            "He brane's date to your for;\n",
            "We whe every which my more wither\n",
            "Edveritige\n",
            "in the eysed with thee,\n",
            "\n",
            "GOLY:\n",
            "Has he foo me asbakn pince that cape a nave\n",
            "Uxtid the garder cannt To dellys:\n",
            "he! 'Lest wor,. but with met's bloadle; and good oncertaie\n",
            "\n",
            "This ifforness wipting hancely of youn vin all, well fourder brother.\n",
            "\n",
            "COMENIE:\n",
            "Fow, leilos, they lond.\n",
            "O grien speep? Mayst thou was a wapling\n",
            "To steed\n",
            "Fellems him doth tight\n",
            "The cords you hove to the wombly, metitain:\n",
            "\n",
            "SICINIUS:\n",
            "The would other, spy ushily in distro's.\n",
            "\n",
            "QUEEN ELIS:\n",
            "Met it by my kind,\n",
            "Whild forend he itinast,\n",
            "Souly, shall great have gounts a trburgutestament.\n",
            "\n",
            "RICHARD:\n",
            "'Tis crave: my brother'ss Man?\n",
            "\n",
            "BAPGONT:\n",
            "Dearw and the plens him jest me at lon mest?\n",
            "\n",
            "Shep, Skis'd shall devingerores,\n",
            "O, what.\n",
            "\n",
            "BUCKINGHY:\n",
            "\n",
            "The know'st were my sop\n",
            "How Gound he's y\n",
            "Whate kings trinimy he gracted, sir, the cous bat hands hor love too comfort of humberabe.\n",
            "\n",
            "PORISSA:\n",
            "Thou have be doond my beon for haning to you?\n",
            "\n",
            "ISCBEUS:\n",
            "Again to swift:\n",
            "Was let that pass'de that I am one off buins and lefter the:\n",
            "But what sword in parkipy in your swear\n",
            "'Tis grave at pitiof Yer beashed you goven Loris our dringe,\n",
            "by quitient\n",
            "That hest, do nat bot with muje behald\n",
            "The coldentirg?\n",
            "\n",
            "GRUMIO:\n",
            "We that's all tho execchath and begie, Evicus! Whlis like has hast the ead the heavery hanct d shou coun'd unb'st be bangeroust, willow and my know would have a fevilfuck, butie's what a carl'd temest\n",
            "To plich of wous thin: sir.\n",
            "\n",
            "GONZALANUS:\n",
            "Here you heavend of this reast\n",
            "That fay them tap\n",
            "shee with as shall speath'd\n",
            "He pled upon'd and marry gut\n",
            "And shemst with them appard toTh on deach a poor\n",
            "Buck your quith heave need querner,\n",
            "Her sighter of such oug.\n",
            "\n",
            "RATRINCI:\n",
            "Hath in you deaph death of deciud, that?\n",
            "\n",
            "VOLUMNIA:\n",
            "Why, my smeece, betber a blother'Y fiest, force oppen I holk, Blonded's weat:\n",
            "Aftendition maich'er well: I dearon of York'd lusish.\n",
            "Therefuse Oth you; sight degives:\n",
            "Were is 'tis kencly,\n",
            "Thy rifter. Har his traced'st prop'stage fouth--buggroy with teets,\n",
            "The mury patcis.\n",
            "\n",
            "GRUMPO:\n",
            "Therecone against on our foul of Angelly of Bose stin, the bows, whan at but accouline's for,\n",
            "Thy henger:\n",
            "There is he war:\n",
            "We wailand agand.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I would\n",
            "The weepselvespory Hance: chimits by his father than, why, fear'd; ray been have have donou haved your prities,\n",
            "That fourned Edwas my joward?\n",
            "Leth any coure to him; come'dress le\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "Epoch 11 Loss 1.4097\n",
            "Time taken for 1 epoch 15.113704919815063 sec\n",
            "\n",
            "Model: \"rnn_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    multiple                  16640     \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    multiple                  1311744   \n",
            "                                                                 \n",
            " dense_13 (Dense)            multiple                  66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,395,009\n",
            "Trainable params: 1,395,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "샘플링을 시작합니다!\n",
            " what ners: I hold, thou shalt manish'd by must: your by Angelo,\n",
            "And do my saddre commonted means;\n",
            "We wilusing more scunding than\n",
            "such propetion thine\n",
            "By yourself true woubs.\n",
            "\n",
            "Nursom: o butchess shall lefter with device, no corrid so longing where no slabe.\n",
            "\n",
            "ESCALUS:\n",
            "More lead me truty live. Bus thou show your hiskle or this shones\n",
            "And thingst upon me flow,\n",
            "How demeeth would no. 'Tis s cends of other to\n",
            "Which that thou mean to on.\n",
            "\n",
            "MIRG EDWARD IV:\n",
            "But larties\n",
            "A dogger me.\n",
            "\n",
            "GLOUCESTER:\n",
            "Thou art trumption which, be threst jurt-shomity rupes' i' the dreaty Clarence, Richmond, hold, hear my lord.\n",
            "\n",
            "CAPULET:\n",
            "This to young men man shall wife, Baptistix will biddle's, thy brothen, comforty there\n",
            "The san of this had and plain will craves drewn to his for what blast by a kind but newire pont auts her too hour in my feer hither,\n",
            "We are you were yound and beceful him\n",
            "To beseechest should thine restlong.\n",
            "\n",
            "Prozed:\n",
            "I'll not reshere\n",
            "to him.\n",
            "\n",
            "TRANIO:\n",
            "Ays my all or worm. Peare my honds? Nor whom that shoplied\n",
            "Than he marry,\n",
            "Come not bless I now the king of such a fair Frincy and my sweet may nore\n",
            "when I canner means, which Rome consenter state;\n",
            "And yet his beliched such a follow Luchard Angelo incoversle dooblehip else\n",
            "condent all:\n",
            "Then jost in words, I prive to the gods and my too unever thou means of brother, wisire,\n",
            "Tunks from the collands, whore that to commander:\n",
            "Your cold, none in a sape to\n",
            "commonsed in this minds are fair wind\n",
            "Give tasbees in threain,\n",
            "And I have I cannot, if a shed! for your hand comp Rupa of our\n",
            "deserve a faults this as I with merriners, or with a most\n",
            "This one to be pleasesy mouth, my leadlest of the duke iven to her cousin ot mo.'\n",
            "Clunder.\n",
            "This, is one sorrow,\n",
            "And make a brod for men; I can must thou rams on's queen; my Lordof; but you through a powsams?\n",
            "\n",
            "STRISHARDIUS:\n",
            "Thou, I shall I' so coundell'd beggs to all the lamber.\n",
            "\n",
            "Lurd: all then thou seens\n",
            "A wind thy rich from hers, my sonstanes 'tok that they hold! therefore I say home; friar Measing. O, the earth of that thet any what once shall have I cannot be living brince\n",
            "List tho trail\n",
            "As Edward's back!\n",
            "\n",
            "BIONTES:\n",
            "O jointred time to himself.\n",
            "\n",
            "LADY WELWESVILIXENES:\n",
            "Vir the sbirt me goner:\n",
            "Bring it is grink had made my gree,\n",
            "Re\n",
            "whatwered: it have merry living woe came\n",
            "To by delace of all too young roth rates.\n",
            "\n",
            "VOLUMNIA:\n",
            "I was and Bolingbrane because,\n",
            "And I eporth thy done:\n",
            "I would not yet whose hame out which'd, or what he writtle lords,\n",
            "God knee-nough.\n",
            "\n",
            "VOLUMNIA:\n",
            "God in my stem;\n",
            "But twofls preselves, then, not a gertle\n",
            "To knowly night: Julier, horsom\n",
            "I war out\n",
            "And knock thy majesty whose one brought the Bourble,\n",
            "The named mine eye\n",
            "do slaubt them?\n",
            "And one though they are this remottected for sensey, how, wench and wordly evee\n",
            "sir! and his master, and they from my heart, Edward work the drows from the moster than thus, my most madour!\n",
            "Thou hast bewower,\n",
            "See, my lord.\n",
            "\n",
            "LADY PERVOLIO:\n",
            "Most I say men when the baunting of the enough.\n",
            "\n",
            "NLOMPEY:\n",
            "\n",
            "O bes word leave this time\n",
            "Hore art\n",
            "do brink I do, 'eepellany and sprepwert to usproce to sprith?\n",
            "\n",
            "PEANTA:\n",
            "Good may me word to that word to thee,\n",
            "Dean a king, wimed carning for the king\n",
            "Than done may she bard to infured you,\n",
            "And we have longes, those mother, ert thy dull me to are befome,\n",
            "Nor though wronge to stan we moat,\n",
            "A news and what stay hatise on this speak drum Loran their chmice;\n",
            "'Tis Baphare Was to bed roim,\n",
            "And where's wife you mechermed back anturn ever sor; in mercely no line.\n",
            "\n",
            "HASTINGS:\n",
            "I do with him of moreofleman:\n",
            "' hands you to say never that oney? What low you what\n",
            "I have more tongue,\n",
            "And will one words with hour. Thou bloody wond on the earth.\n",
            "\n",
            "PETRUCHIO:\n",
            "I will are controus, for who looks and warst those and re\n",
            "My steaster than my lady off of Tongue.\n",
            "Call the night,\n",
            "And thou, work: if that\n",
            "Alace, combrant sweet breast.\n",
            "The livery endings blame\n",
            "As recenver is most charand'st which hold more, housely, or ince threft,\n",
            "Or crest will you me fail crow.\n",
            "\n",
            "Provost:\n",
            "Tongue syin, I wom not drink-lander quorer enty a boes a rig\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "Epoch 16 Loss 1.3710\n",
            "Time taken for 1 epoch 15.124552011489868 sec\n",
            "\n",
            "Model: \"rnn_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    multiple                  16640     \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    multiple                  1311744   \n",
            "                                                                 \n",
            " dense_14 (Dense)            multiple                  66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,395,009\n",
            "Trainable params: 1,395,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "샘플링을 시작합니다!\n",
            " Eggot to the matter\n",
            "Julieve betweentier by the time igness\n",
            "I must I here, signiarty had she wealth,\n",
            "Nor ashow you do not will die and baithen are to tyranted\n",
            "I'll still she have soldiers,\n",
            "Even even to a trainoushatio.\n",
            "\n",
            "POMPEY:\n",
            "Tug as one too, sir,\n",
            "Lary is the crownfard,\n",
            "And beague she bud stands forthwith children, to make him for him;\n",
            "And tume I may ere as we do so as to send me the deems. Widow, Grief, take him when they are, here's joy of duft\n",
            "Of pardon prayers, with spech with child! I band me why, the threeconsents, Henry, and every heart;\n",
            "A pride!\n",
            "\n",
            "ISABELLA:\n",
            "You'll not: marry, the hadse in the king is base and small common a child? and more, how were which attle for this spides and you meet tongue to-mirrow;\n",
            "But then so housesire--\n",
            "\n",
            "SEBASTIAN:\n",
            "O, here's as a work.\n",
            "\n",
            "EOMNO:\n",
            "Is the poor more words come, it would,\n",
            "Good firsh where they kiss me for it, marry, Marcius, ter,\n",
            "Where no more, granted in again: where, amat, my lord; I have have been some feath;\n",
            "So then to the house that touching till that have bid me not, dear put her lordship for I say ha!\n",
            "\n",
            "GLOUCESTER:\n",
            "Why have himself may stuffud our mother light; he is here as e fled of York so traitor mand of those to this father I be marry vartul.\n",
            "\n",
            "CLIFFORD:\n",
            "Ay, as he be pretty head of prisonce had one hiave or drop!\n",
            "\n",
            "SAM:\n",
            "Therefore, when therefore thou takest the ware with beary, chanow.\n",
            "\n",
            "QUEEN MARGARES:\n",
            "She is an ords to make hence, I am the heart.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "Who had 's in the colours, then here to stoorphes agreed;\n",
            "And mere you safe, our sendiers of the bastard and you the turnoy, sire,\n",
            "That, was not your state was tongue,\n",
            "After, good fair of mine eyes are that is my end;\n",
            "In breasure it, but sovereign premilestance have more as, morion't, doth in such man to sure: Whose more yours, leg him loigness, from youbless done, privain worth, and she then set you can the corse we came, what, in London Judour, how Forst take the people, phyaltenger:\n",
            "Thou hast thou articled glory:\n",
            "I am but one that I rock\n",
            "I maze that would them to sword, go a gussfur fire battle behold, as I have it sleep look upon cousin, she hath held a chance\n",
            "Or bainted gall'd life:' hither where come ton crefer of merrews: I shall go at odds breek?\n",
            "\n",
            "SICINIUS:\n",
            "He love up, you will bid the sum Shall knew our father: now Pray, my brother, sirror, so there?\n",
            "\n",
            "PROSPERO:\n",
            "Nay, by the oare all whenes to me they Roman some sorrows by the earth, thou might out, meatuty, and I have to sorry that can they have show to the restips his head,\n",
            "\n",
            "home hours against-other at ancreatest die: to be plauze you operfort\n",
            "So an arry, on this birds in holy.\n",
            "Thy face this more methink here with the\n",
            "Than thee him;\n",
            "And pited I'll meou thee nothing still\n",
            "For then at your girty; call'd, I think if not t, it makes the ten himself come at the head,\n",
            "To set their motness forth me from me made tonguement.\n",
            "\n",
            "MENENIUS:\n",
            "Not him they must stabl'd she would assafe encestor\n",
            "Shall lie, in that thou want their way!\n",
            "Because that if her shall prove aore fuelved, are you have provett\n",
            "I water at once\n",
            "To many your can, and but in a strout thy drinks be into their own bay, if the desire I one our subjects hare to-day doubt hell.\n",
            "Hear me to Exetion:\n",
            "And some Juliet hath so fear can in this station\n",
            "But that of fairty to see your mother then, his shrew our compand for grief of this name is with her a kindred too madams\n",
            "Upon the son I do fear him hash\n",
            "The crown; Romeo heaven yet thy matter for our day;\n",
            "at obey?\n",
            "\n",
            "PROSPERO:\n",
            "Come, is, I cerem't that caliments\n",
            "To fareword, godd to fortune\n",
            "Wontets that epil that walk not when he pitle with the corsom to Ladie.\n",
            "\n",
            "GLOUCESTER:\n",
            "\n",
            "First Servant:\n",
            "They winow the world, I call thee I am in the EngEANUS:\n",
            "\n",
            "Stell they are veward, subar\n",
            "Till he out of him thee, here comforts himself, the truthous sorrow'st out on majesty,\n",
            "And till\n",
            "I taught wreak by the Kengers fier\n",
            "And by the commit o', a dower mottow on, an 't you the twing\n",
            "Too poor or else, I, every taintly is a rest,\n",
            "And II:\n",
            "Why once marry rise-wand thou art him, take the prince\n",
            "샘플링이 끝났습니다.!\n",
            "------------------------------------------------------\n",
            "트레이닝이 끝났습니다!\n"
          ]
        }
      ],
      "source": [
        "# Recurrent Neural Networks(RNN) 모델을 선언합니다.\n",
        "RNN_model = RNN(batch_size=batch_size)\n",
        "\n",
        "# 데이터 구조 파악을 위해서 예제로 임의의 하나의 배치 데이터 에측하고, 예측결과를 출력합니다.\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = RNN_model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "# 모델 정보를 출력합니다.\n",
        "RNN_model.summary()\n",
        "\n",
        "# checkpoint 데이터를 저장할 경로를 지정합니다.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  start = time.time()\n",
        "\n",
        "  # 매 반복마다 hidden state를 초기화합니다. (최초의 hidden 값은 None입니다.)\n",
        "#  hidden = RNN_model.reset_states()\n",
        "  if (epoch) < 2:\n",
        "    sampling_RNN_model = RNN(batch_size=1)\n",
        "  #  sampling_RNN_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "    sampling_RNN_model.build(tf.TensorShape([1, None]))\n",
        "    # 샘플링을 시작합니다.\n",
        "    print(\"초기 샘플링을 시작합니다!\")\n",
        "    print(generate_text(sampling_RNN_model, start_string=u' '))\n",
        "    print(\"초기 샘플링이 끝났습니다.!\")\n",
        "    print ('------------------------------------------------------')\n",
        "\n",
        "  for (batch_n, (input, target)) in enumerate(dataset):\n",
        "    loss = train_step(RNN_model, input, target)\n",
        "\n",
        "    # if batch_n % 100 == 0:\n",
        "    #   template = 'Epoch {} Batch {} Loss {}'\n",
        "    #   print(template.format(epoch+1, batch_n, loss))\n",
        "\n",
        "  # 5회 반복마다 파라미터를 checkpoint로 저장합니다.\n",
        "  if (epoch) % 5 == 0:\n",
        "    RNN_model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "    print ('------------------------------------------------------')\n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
        "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "    sampling_RNN_model = RNN(batch_size=1)\n",
        "    sampling_RNN_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "    sampling_RNN_model.build(tf.TensorShape([1, None]))\n",
        "    sampling_RNN_model.summary()\n",
        "    # 샘플링을 시작합니다.\n",
        "    print(\"샘플링을 시작합니다!\")\n",
        "    print(generate_text(sampling_RNN_model, start_string=u' '))\n",
        "    print(\"샘플링이 끝났습니다.!\")\n",
        "    print ('------------------------------------------------------')\n",
        "\n",
        "\n",
        "\n",
        "RNN_model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "print(\"트레이닝이 끝났습니다!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYRWH64OQ2LG",
        "outputId": "7619d9f1-e247-45e7-f3a8-a4af0a9f034b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"rnn_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    multiple                  16640     \n",
            "                                                                 \n",
            " simple_rnn_7 (SimpleRNN)    multiple                  1311744   \n",
            "                                                                 \n",
            " dense_15 (Dense)            multiple                  66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,395,009\n",
            "Trainable params: 1,395,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "샘플링을 시작합니다!\n",
            " what a steciains. For they, Mancusa seeming boy:\n",
            "For I know furth after thy favour wicked friendly lord, they see:\n",
            "you see her thieves; ay, sweet soint lost I am\n",
            "Taught to destroy that appeal,\n",
            "So she is groat Eable coornow-bocked on his high despair thy hate,\n",
            "In that do: gazens\n",
            "Common service; this comfort. But I, that far I know no itself I am in this day shall not dead, as fand,' leave\n",
            "They would be king, aunts, men's to\n",
            "come forth thy father show'd, impubs,\n",
            "For so: or bouster him seem'd\n",
            "At all there.\n",
            "\n",
            "QUEEN ELIZABELLA:\n",
            "A bloods, and so fiery Town, thrives I for revenge and the rest was before:\n",
            "My gives my namos--\n",
            "For it stopp'd by himself\n",
            "All trook like, stands adors.\n",
            "\n",
            "DORGOLIO:\n",
            "\n",
            "JULIET:\n",
            "What, art thou do been before,\n",
            "Scalfforrow to chaste-mair to be spoop cheer'd the glow that he shall marchase tenire than most knights,\n",
            "And deathless daughter\n",
            "You never scarce death,\n",
            "Shall clise exocks.\n",
            "\n",
            "NORTHUMBERLANDO:\n",
            "Is this gentleman.\n",
            "And, letter ye, he know what such walls and tainted wear.\n",
            "And, Aufidius,\n",
            "And I'll accommend guedation on the vale prattle freell of God\n",
            "Fellow, but in my stones.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "As think he shall never go almest:\n",
            "Aback thee, here?\n",
            "\n",
            "RIVERS:\n",
            "That hath shall take gone!\n",
            "Where Mortal to beseech their own leose:\n",
            "How comes are rut to the\n",
            "beat my curse,\n",
            "Your highness\n",
            "from he did: having not the depution and free present\n",
            "To save you to thee all them we that flourise women can have heard you of it. That ennows.\n",
            "Maid that you then, till I hide no people and caught me from the fixain Sapls\n",
            "But what I have bided.\n",
            "\n",
            "KATHARINEN:\n",
            "When he; you are gone,\n",
            "That was he whose gracing than beasth;\n",
            "Fee, seek some fond lips, Thoughness and over horse:\n",
            "Perdite, I tell you now? \n",
            "First Gentleman:\n",
            "Nay, I am send at\n",
            "your hate taste Murderer:\n",
            "Why, that yet be\n",
            "with me to false;\n",
            "And he so buss this land as false burstramehold\n",
            "As yields discle-gainor's regall'd\n",
            "With me I am noble innocenc.\n",
            "\n",
            "PETRUCHIO:\n",
            "A' shall that she's curst way\n",
            "Because thou art against him from me that we was clomes.\n",
            "\n",
            "GLOUCESTER:\n",
            "Will he gell no mourn to take he sent thy blight as face thee near.\n",
            "\n",
            "CORIOLANUS:\n",
            "\n",
            "PARIS:\n",
            "What comes you were strawally.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "If I get is fire, goodly thou vexflict'st hath some chaight.\n",
            "\n",
            "Third Citizen:\n",
            "Come, by this young Rome and lend and life thee\n",
            "His, i' the deep as a fatch'd England!\n",
            "\n",
            "BAPTISTA:\n",
            "See the palfle dropb'd it,' and no sin?\n",
            "Our part of Margalet.\n",
            "\n",
            "CAMILLO:\n",
            "Sinive he is\n",
            "counters, and thou be emblorious; that can give me upst against your coist\n",
            "Shall see you needs me quiet another star;\n",
            "The matcherch other substance\n",
            "All unknown so long like cold:\n",
            "And, that would meet me so sweet titness passal ciect sheep, by the baggars\n",
            "No brawlf am I tell you know you'll thrust us contenting child, he were gone as, by the pripets.\n",
            "\n",
            "ANTONIO:\n",
            "Forget the rest and ceas from himself?\n",
            "\n",
            "Nurse:\n",
            "Sorto'd love,\n",
            "I'll be spre with a man as endering.\n",
            "\n",
            "PETRUCHIO:\n",
            "Why, thy threased.\n",
            "Speak?\n",
            "\n",
            "First Citizen:\n",
            "Holiful in thy masters desire for several poor bosom.\n",
            "\n",
            "RICHARD:\n",
            "Noy, admonio.\n",
            "\n",
            "Second ye, fair peace, a gite.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Earl, so, Good many then as light'\n",
            "Tawe, and Seeking them fear, fat laid?\n",
            "\n",
            "ANRIAN:\n",
            "I do bear me by a fielded out.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "I'll have deparal too\n",
            "These fierchy fellow.\n",
            "\n",
            "First Officer:\n",
            "But that thy tide,\n",
            "And to redeen them speak\n",
            "they\n",
            "Shalt thou knay,\n",
            "The musicious.\n",
            "\n",
            "KING RICHARD III:\n",
            "Fool, is it cordleng down.\n",
            "\n",
            "Nurse:\n",
            "Go, come with Saint MORELLE:\n",
            "My lord!\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Ment it not, yet she came to thee,\n",
            "Which, say, let's stink'lly is\n",
            "changest.\n",
            "\n",
            "First Murderer:\n",
            "Well, let\n",
            "You hear thee;\n",
            "They longet heret that thy shame\n",
            "been can by what, with mine own desires.\n",
            "\n",
            "ISABELLA:\n",
            "Your leaveness; thenking night thyself;\n",
            "Nor which seeking there would salk be not years of spould a man as yourselves is dead,\n",
            "Reseeded the queen's\n",
            "dequiet and the shore against thee.\n",
            "\n",
            "LUCENTIO:\n",
            "I peace am I twhich thy deather's.\n",
            "\n",
            "CAMILLO:\n",
            "Yiunable desequent\n",
            "that which else deservidech me do in their\n",
            "open.\n",
            "\n",
            "First Sulkill'd me:\n",
            "He's in that here from me\n"
          ]
        }
      ],
      "source": [
        "sampling_RNN_model = RNN(batch_size=1)\n",
        "sampling_RNN_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "sampling_RNN_model.build(tf.TensorShape([1, None]))\n",
        "sampling_RNN_model.summary()\n",
        "\n",
        "# 샘플링을 시작합니다.\n",
        "print(\"샘플링을 시작합니다!\")\n",
        "print(generate_text(sampling_RNN_model, start_string=u' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uQirp-BkLwpG"
      },
      "outputs": [],
      "source": [
        "# %run train_and_sampling.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiMsKK7upSQN5nzOPqbngu",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}